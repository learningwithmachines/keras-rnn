<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>RNN_project</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Artificial-Intelligence-Nanodegree">Artificial Intelligence Nanodegree<a class="anchor-link" href="#Artificial-Intelligence-Nanodegree">&#182;</a></h1><h2 id="Recurrent-Neural-Network-Projects">Recurrent Neural Network Projects<a class="anchor-link" href="#Recurrent-Neural-Network-Projects">&#182;</a></h2><p>Welcome to the Recurrent Neural Network Project in the Artificial Intelligence Nanodegree! In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with <strong>'Implementation'</strong> in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully!</p>
<blockquote><p><strong>Note:</strong> Code and Markdown cells can be executed using the <strong>Shift + Enter</strong> keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementation-TODOs-in-this-notebook">Implementation TODOs in this notebook<a class="anchor-link" href="#Implementation-TODOs-in-this-notebook">&#182;</a></h3><p>This notebook contains two problems, cut into a variety of TODOs.  Make sure to complete each section containing a TODO marker throughout the notebook.  For convenience we provide links to each of these sections below.</p>
<p><a href="#TODO_1">TODO #1: Implement a function to window time series</a></p>
<p><a href="#TODO_2">TODO #2: Create a simple RNN model using keras to perform regression</a></p>
<p><a href="#TODO_3">TODO #3: Finish cleaning a large text corpus</a></p>
<p><a href="#TODO_4">TODO #4: Implement a function to window a large text corpus</a></p>
<p><a href="#TODO_5">TODO #5: Create a simple RNN model using keras to perform multiclass classification</a></p>
<p><a href="#TODO_6">TODO #6: Generate text using a fully trained RNN model and a variety of input sequences</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Problem-1:-Perform-time-series-prediction">Problem 1: Perform time series prediction<a class="anchor-link" href="#Problem-1:-Perform-time-series-prediction">&#182;</a></h1><p>In this project you will perform time series prediction using a Recurrent Neural Network regressor.  In particular you will re-create the figure shown in the notes - where the stock price of Apple was forecasted (or predicted) 7 days in advance.  In completing this exercise you will learn how to construct RNNs using Keras, which will also aid in completing the second project in this notebook.</p>
<p>The particular network architecture we will employ for our RNN is known as  <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Long Term Short Memory (LSTM)</a>, which helps significantly avoid technical problems with optimization of RNNs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.1-Getting-started">1.1 Getting started<a class="anchor-link" href="#1.1-Getting-started">&#182;</a></h2><p>First we must load in our time series - a history of around 140 days of Apple's stock price.  Then we need to perform a number of pre-processing steps to prepare it for use with an RNN model.  First off, it is good practice to normalize time series - by normalizing its range.  This helps us avoid serious numerical issues associated how common activation functions (like tanh) transform very large (positive or negative) numbers, as well as helping us to avoid related issues when computing derivatives.</p>
<p>Here we normalize the series to lie in the range [0,1] <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html">using this scikit function</a>, but it is also commonplace to normalize by a series standard deviation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Load in necessary libraries for data input and normalization</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">keras</span><span class="o">,</span> <span class="nn">lime</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">keras.utils.data_utils</span> <span class="k">import</span> <span class="n">get_file</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="o">*</span>
<span class="c1"># from my_lstmm import *</span>
<span class="c1"># from lstmm_Udacity_passing import *</span>

<span class="c1">###tflow_memory</span>
<span class="k">def</span> <span class="nf">clear_start</span><span class="p">(</span><span class="n">clear</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="n">K</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">K</span><span class="o">.</span><span class="n">set_session</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">cfg</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">clear</span><span class="p">:</span>
        <span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

<span class="c1">### load in and normalize the dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;datasets/normalized_apple_prices.csv&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets take a quick look at the (normalized) time series we'll be performing predictions on.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># lets take a look at our time series</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;time period&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;normalized series value&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[62]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Text(0,0.5,&#39;normalized series value&#39;)</pre>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXl4W2eVuN8jybZsy/tux47j7E7SpI27t3SnGzRl2FqmQ2FgCgMMDDAMhWHoDMuPMgPDPkxLKdtAW1pgKKX7SvfWabNvThzbcbzvkmxLlvT9/rhXsmzLthxLli1/7/PcR7r3fvfe48TW0dlFKYVGo9FoNPPFkmgBNBqNRpMcaIWi0Wg0mpigFYpGo9FoYoJWKBqNRqOJCVqhaDQajSYmaIWi0Wg0mpigFYpGo9FoYoJWKBqNRqOJCVqhaDQajSYm2BItwEJSWFioqqurEy2GRqPRLCl27tzZo5Qqmm3dslIo1dXV1NfXJ1oMjUajWVKISHM067TLS6PRaDQxQSsUjUaj0cQErVA0Go1GExO0QtFoNBpNTNAKRaPRaDQxIaEKRUTuFpEuEdk3zXkRke+LyFER2SMiZ4Sdu1lEGszt5oWTWqPRaDSRSLSF8nPgqhnOXw2sNbdbgB8DiEg+cBtwNnAWcJuI5MVVUo1Go9HMSEIVilLqL0DfDEt2AL9UBq8AuSJSBlwJPKGU6lNK9QNPMLNi0mgACAQU977WwojXn2hRNJqkI9EWymxUACfC9lvNY9Mdn4KI3CIi9SJS393dHTdBNUuD15r6uPX3e7n39ZZEi6LRJB2LXaFIhGNqhuNTDyp1p1KqTilVV1Q0a+cATZKz7+QgAE8f6kqwJBpN8rHYFUorUBm2vwJom+G4RjMjQYXyamMfbo8vwdJoNMnFYlcoDwLvN7O9zgEGlVLtwGPAW0UkzwzGv9U8ptHMyL62IQodqXj9AV442pNocTSapCLRacP3AC8D60WkVUQ+JCIfFZGPmkseBhqBo8BPgI8BKKX6gK8Cr5vbV8xjGs20DHt9HOt28d4zK8my23j6oHZ7aTSxJKHdhpVSN85yXgEfn+bc3cDd8ZBLk5wcbB9CKdhWmUdT7zBPH+4iEFBYLJFCchqNZq4sdpeXRhMz9p0cAmBzRTaXbSim2+lhX9tggqXSaJIHrVA0y4Z9JwcpdKRSmm3n4vXFiMAzh3QquUYTK7RC0Swb9rUNsak8BxEhPzOV2rJsXj3em2ixNJqkQSsUzbJgdMxPQ6eTzRXZoWNnVufzZssAY/5AAiXTaJIHrVA0y4LDHU58AcXm8pzQsbrqPEbG/BxoG0qgZBpN8qAViiYp+cqfDvDLl5tC+3vMgsbNFeMK5czqfABeb9IZ5xpNLNAKRZOU/O6NVn7xUlNo/9XGXkqz7azISw8dK8m2U5WfoRWKRhMjtELRJB3O0TEGR8Y41u2mc2gUpRSvNPZxTk0+IhNrTuqq86hv6scoedJoNPNBKxRN0nFyYCT0/qVjPRzrdtHj8nBOTcGUtWdW59Pr9tLY415IETWapCShlfIaTTxo7QtTKEd7cXmM2Sfnro6kUIy5bPVNfawuciyMgBpNkqItFE3S0do/DBjK4qVjvbxyrJeyHCNeMpnVRQ7yMlJ4val/ocXUaJIOrVA0ScfJgRHSbBbevrWckwMjPHWok3NrCqbETwBEhG2VuaG29hqN5tTRCkWTdLT2j1CRl875awoBGB0LRIyfBFld5OB4j5tAQAfmNZr5oBWKJuk4OTDCirwMagozKclOAyLHT4LUFDnw+AITgvkajWbuaIWiSTpa+0eoyE1HRLhsYwmrizIn1J9MpqYoE0Bnemk08yShWV4ichXwPcAK3KWUun3S+e8Al5i7GUCxUirXPOcH9prnWpRS1y2M1JrFzLDXR5/bG1Igt729Fq8vEDF+EiSkULpdXLSuaEHk1GiSkYQpFBGxAj8CrsCYEf+6iDyolDoQXKOU+nTY+n8ATg+7xYhSattCyatZGpzsN9xWQYWSZrOSZrPOeE2RI42sNBuN3dpC0WjmQyJdXmcBR5VSjUopL3AvsGOG9TcC9yyIZJolS+skhRINIkJNUSaNPa54iaXRLAsSqVAqgBNh+63msSmIyEpgFfB02GG7iNSLyCsicn38xNQsJVoHggplas3JTNQUObSFotHMk0QqlEhO7enyNm8AHlBK+cOOVSml6oD3Ad8VkdURHyJyi6l46ru79XS+ZKe1f5hUq4UiR9qcrqspzKR9cJRhry9Okmk0yU8iFUorUBm2vwJom2btDUxydyml2szXRuBZJsZXwtfdqZSqU0rVFRXpgGuy09o/QnmuHYtl+iB8JGrMtivHdaaXRnPKJFKhvA6sFZFVIpKKoTQenLxIRNYDecDLYcfyRCTNfF8InA8cmHytZvlxsn9kzu4uCM/00gpFozlVEqZQlFI+4BPAY8BB4LdKqf0i8hURCU8BvhG4V03sL74RqBeR3cAzwO3h2WGa5UuwBmWurCrMREQrFI1mPiS0DkUp9TDw8KRjX560/28RrnsJ2BJX4TRLjtExPz0uDxVzyPAKYk+xUp6TrjO9NJp5oCvlNUnDiT6jy3CkrsLRUFOUqS0UjWYeaIWiSRqaew2FsrLg1BTK6iIHjd0u3SRSozlFtELRJA1NvYZ1sbIg85Su31qZg9vr50D7UCzF0miWDVqhaJKGlr5hsuw28jJSTun6c2uMdvevNPbGUiyNZtmgFYomaWjqHaa6IHPGRpAzUZpjp6Ywk5ePaYWi0ZwKWqFokoaWXjdVpxg/CXLO6gJeO96Hzx+IkVQazfJBKxRNUjDmD9DaP0L1PBXKuTUFOD0+9rXpOIpGM1e0QtEkBW0DI/gCipX5pxaQDxIcFazdXhrN3NEKRZMUzDdlOEhRVhprix28rAPzGs2c0QpFkxQ0zzNlOJxzVxdQ39THmI6jaDRzQisUTVLQ3DuMPcVCcdbc2tZH4pyaAoa9fvadHIyBZBrN8iEqhSIiF4jIB833RSKyKr5iaTRzo6l3mJX5mXNuWx+JLRU5ALrAUaOZI7MqFBG5Dfg88AXzUArwv/EUSqOZKy19808ZDrIiL50su42DWqFoNHMiGgvlHcB1gBtCg62y4imUZnHh9QW497WWRVubEQgomnuH550yHERE2FiWzQGdOqzRzIloFIrXnEWiAERk/lFPzZLiqYOd3Pr7vTx7eHGOUO5yevD4AlTFICAfpLYsm0MdTt0oUqOZA9EolN+KyB1Aroj8HfAk8JP4iqVZTBzrNmaE1Df3J1iSyBzudAKw8hTb1keitiybYa+fFrMlvkajmZ1ZFYpS6lvAA8DvgPXAl5VSP4jFw0XkKhE5LCJHReTWCOc/ICLdIrLL3D4cdu5mEWkwt5tjIY8mMsEZITub+xIsyVQCAcV3njhCoSONM1bmxey+G8uyAR2Y12jmQlQTG5VSTwBPxPLBImIFfgRcAbQCr4vIgxFG+d6nlPrEpGvzgduAOgxX3E7z2sX5FXqJc6zHUCi7Wwfx+gKk2hZPtvl99SfYdWKA77x3K4602A0gXVviwGoRDrYPcc2WspjdV6NJZqLJ8nKKyJC5jYqIX0Ri8bXtLOCoUqpRKeUF7gV2RHntlcATSqk+U4k8AVwVA5k0k1BK0djtojTbjtcXYF/b4qnN6HN7+eajhzh7VT7Xb6uI6b3tKVZWF2XqwLxGMweicXllKaWyzc0OvBP4YQyeXQGcCNtvNY9N5p0iskdEHhCRyjleq5knPS4vzlEff3WG8c+7s2nxGIH/+0ozgyNjfPX6zafcsn4masuydeqwRjMH5uy7UEr9H3BpDJ4d6RNgckrNn4BqpdRpGMkAv5jDtcZCkVtEpF5E6ru7F2eW0mKm0QzIn11TQFV+BvWLKI7S0OWiMi+DdSXxyWLfWJZN2+AoA8PeuNxfo0k2onF5/VXY9i4RuZ1pPrznSCtQGba/AmgLX6CU6lVKeczdnwDbo7027B53KqXqlFJ1RUVFMRB7edFoxk9qCjOpW5nHzuZ+jCzyxNPc6553M8iZqC3XgXmNZi5EY6G8PWy7EnASfaxjJl4H1orIKhFJBW4AHgxfICLh0dDrgIPm+8eAt4pInojkAW81j2liTGO3izSbhYrcdLZX59Hj8oY6+yYSpRTHe9xUx7D2ZDK1wUwvHUfRaKJi1rQYpdQH4/FgpZRPRD6BoQiswN1Kqf0i8hWgXin1IPBJEbkO8AF9wAfMa/tE5KsYSgngK0qpxeOLSSIau92sKjR6ZNWtzAdgZ3M/1YWJrW8dGB7DOeqLq4VS4EijIjed3a2LJxFBo1nMTKtQROQHzODaUkp9cr4PV0o9DDw86diXw95/gfEeYpOvvRu4e74yaGamscfNxjIjRrG6KBMRFkWxX5PZrj6eFgrA1socdp8YiOszNJpkYSYLpX7BpNAsSry+AC19w1xr1mHYrBbyM1LpdnlmuTL+BN1u1YXxs1AAtq7I5eG9HfS6PBQ45t8aX6NJZqZVKEqpX0x3TrM8aOkbxh9QrApzbxVlpdHtjL9Cee5INx/91U5sViEvI5Uf33QGm8pzQuebe4cRgRV5cVYolbkA7Gkd5JINxXF9lkaz1Ikmy6tIRL4lIg+LyNPBbSGE0ySWYMpwTdHCK5QXGrrxK8U7z1hBl3OUe187MeF8c6+b8px07CnWuMqxpSIHi8Au7fbSaGYlmiyvX2NkV60C/h1oYjwYrklSuoZGue9140O8psgROl7kWBiFcqjDyfqSLP7tuk1ctrGEh/e2T2if3xTnlOEgmWk21hZnsbtVKxSNZjaiUSgFSqmfAmNKqeeUUn8LnBNnuTQJ4li3i288fJCLv/Usf2no5lOXrSUnPSV0vigrjW6XJ+61KAfbnWwoNZIBrttaTq/by0vHekPnm3uHYzI/PhqCgfnFUn+j0SxWoummN2a+tovItRgFhCviJ5ImUXzs1zt5eG8HVotw9eZSPnfl+ikf2kVZaXh9AYZGfeSkp9DU46Z9cJRzVxfETI5up4cel4cNZh3IReuKyEqz8afdbbxlXRFDo2P0ur0xG6g1G1src/ltfSsn+kZiNhVSo0lGorFQviYiOcBngX8C7gI+HVepNAtOIKB4dF8Hb60t4eUvXMoP33dGRAugKMvIdAq6vf7riSP8wz1vxlSWwx3GfJONpoViT7Hy1k2lPLq/A4/PT4uZ4bVgFsoKIzC/S7u9NJoZiUahvKqUGlRK7VNKXaKU2m4WHWqSCOeoj4CCs1blU5xln3ZdkWOiQmnqddPj8uD1xW488KEOozJ9fel4j663by3DOerjmUPd4zUocU4ZDrK+NIs0m4VdLVqhaDQzEY1CeUlEHheRD5ltTjRJSL/ZADEvI3XGdSELxaxFCdaDxLI25WC7k+KstAl1H+evKaQ8x86X/m8vj+/vBKAqhhMaZyLFaqGuOo9nj3RFFUe57Y/7+LcH9y+AZBrN4iKa9vVrgS8BmzAGWT0kIjfFXTLNgtJnKpT8zCgVitPD4PAYgyNGiK1zaDRmshzqGArFT4KkWC386sNnk2K18ODuNoqz0shIjd1Ardm4alMpjd1uGrpcM65TSvHQnnbeaFk8bf41y5uFTCaJqn29Uuo1pdRnMIZi9THeRl6TJARbtOdmpMy4Lic9hRSr0O300NznDh3vipFC8fkDNHS6QvGTcFYXObj/o+eyqjCTTeXZEa6OH1duKkUEHtnbMeO61v4Ret1eXKO+BZJMo5mZZ490c/7tT3Ok0xn3Z0VT2Jhtzm9/BHgJaMdQLJokot9tWBqzubxEJFSLEt7Tq3MoepeXzx/g8f0dEb85He9x4/UH2FAWecbJirwMHvnUhfz4pu0Rz8eL4mw7dSvzeGRf+4zr9piNJJ0erVA0i4NdLQO0DY5Qnpse92dFY6HsBrZhdPRdp5T6vFJqZ5zl0iww0cZQYLwWJRg/scjcXF5PH+rill/t5MWjvVPOHTQzvDaUTm+B2FOsca+Qj8RVm8s41OHkeI972jV7zEwwbaFoFgu7WwdYV5yFIy3+LuJoFEqNUurTSqmX4y6NJmEMDI9hEciyz/5LF2y/0tI7TKEjjZJs+5wslODQrp3NU+MMB9uHsFmE1WHV+YuFqzaXAsxopQRbtIyM+SdU9ms0iUApxe4TA2ytzJl9cQyIJiivy4OXAf3DXnIzUrFYZp/NHlQozX1uqvLTKc620+WM3kJpNtN+3zwxUaF4fQEe3NXGGVV5pNrmPJ067lTkprO1MpfHzCyzyfgDin0nB0m1GrK7vf6FFE+jmUJL3zD9w2Nsq1yYBN3F91erSQgDw2PkzRKQD1LkSKPP7aGpx2h/UpqdNieXV1OP4Sp7s2WAQGD8+8oDO1s5OTDCxy5ZPTfhF5DtVXkc6XBGjP80drtwe/2cXmUUQrp0HEWTYIIW86KxUOKJiFwlIodF5KiI3Brh/GdE5ICI7BGRp0RkZdg5v4jsMjddaDlP+tzeqOInYFgoAQUdQ6NU5WfM2eXV3OsmzWZhcGSM46a14vUF+NEzR9lamctF64pO6WdYCFbkpTMy5qfP7Z1yLvjHe/6aQkDHUTSJZ9eJAewpFtaXRE5yiTXRZHn9h5nplWJ+qPfEog5FRKzAj4CrgVrgRhGpnbTsTaBOKXUa8ADwH2HnRpRS28ztuvnKs9wJuryiIViLArCywFAogyNjjI7N7uIZHfPTNjjKFbUlgGGlAPz+DcM6+cfL1yIyu9stUVSaxZSt/SNTzu1pHcSRZmPLCuPboMszNmWNRrOQ7DoxwJaKHGzWhbEdonnKW5VSQ8DbgFZgHfC5GDz7LOCoUqpRKeUF7gV2hC9QSj2jlArmpr6CbkoZN+bk8pqkUIrN/a4orJQTZqrxZRuLybLbeKOlnxGvnx88fZStK3K4eBFbJ2BYKBBZoexuNf54s+3Gv6PLo2MomsTh9QXY3zbENnNI3EIQjUIJfspcA9yjlOqL0bMrgPCpSa3msen4EPBI2L5dROpF5BURuX66i0TkFnNdfXd39/wkTmL6h73kzVIlH6TIMd7rq9J0eQF0RhGYbzJTjVcVOthWmcubLQPc8ZdjnBwY4QvXbFzU1glAhalQTvQPTzgeCCgOdTjZXJEdypTTLi9NIjnUMYTXF1iwgDxE177+TyJyCBgBPiYiRUAsyqIjfXJEzCgzXWx1wEVhh6uUUm0iUgM8LSJ7lVLHptxQqTuBOwHq6up0xloERrx+PL7ArFXyQQqzDMWTkWqlyJFGf3b07VeCGV6rCjI5vSqPHz7dQGO3i2tPK+Ocmti1wI8X2fYUctJTaJ2kUPqGvXh9ASpy00P5/trlpUkkuxc4IA/RpQ3fCpyLEcsYA4aZ5Jo6RVqByrD9FRizViYgIpcD/wJcp5QK+VSUUm3mayPwLHB6DGRalgSLGvOjjKFkpNpwpNmoys9ARCjJNlxe0wXmO4dGaR80XETHe9zkZqSQk5HCGVW5BBSIwBev2RiDn2RhqMxPn+Ly6hg0lGlpjp1MU6E4tYWiSSBHOl1k221ULECFfJBogvIZwMeBH5uHyjGshfnyOrBWRFaJSCpwAzAhW0tETgfuwFAmXWHH80QkzXxfCJwPHIiBTMuS/lAfr+gUChixhNXFRvFhTnoKqTbLtP28bv3dHv76rldRSk2YtHh6ZR4ZqVb+4dK1C/pLP19W5GZMUShB66wk2x5moWiFokkcfW4vhVlpC+pGjsbl9TNgJ3Ceud8K3A88NJ8HK6V8IvIJ4DHACtytlNovIl8B6s2ZK/8JOID7zX+UFjOjayNwh4gEMJTi7UoprVBOkfE+XtG5vAB+fNN2MlON9idBK2U6l1dL3zCN3W5ePd5HU6+b7SsNn25ORgqvfPEyshagJUQsWZGXHmplH/xj7Rgat1CsFiEj1YpbK5Sk5lDHEHtbB3l3XeXsixNAn9sbtdchVkTzl7xaKfVeEbkRQCk1IjFSeUqph4GHJx37ctj7y6e57iVgSyxk0IT18YoyKA+wqnDitMSSLHvoQ3UyweyvX73cTNvACH91xniyXjAjaimxIi+d0bEAPS5vKOOtc3AUESg0Z7g40mzaQkly/uvxIzxxsNOY1bMILez+YW8ozX2hiCbLyysi6ZgBcxFZDcRumpIm4UTbun4mSrLtEdOG3R4fTo+P9BQrf97bTkCxYLPg48V4Lcp4YL5jaJRCRxopZr6/w27TMZQkxusL8NKxXpSCh/ZMCf0uChJhoUSjUG4DHgUqReTXwFPAP8dVKs2C0j9suLxy00/9l6/YdHk5R8d4vakPv9lSpcscFXzTOVWhtdWFCzMLPl6syJta3Ngx5KE0ezydWlsoyc3O5n5cHh9pNgt/3LX4FIpSak6lALEimiyvJ4C/Aj4A3IOR7fVsfMXSLCT9w16y0mzzashYkm03+lh95Qne/T8v8+RBo4FiMK5y8fpiTjMryKsLlrZCqYhQ3Ng1NBqqxwFToWgLJak42D4U6gbx7JEuUqzCJy5Zw/62IY7OMslzoXF5fIz5FfmZC+tSnvYTREQ2mK9nACsxBmu1AVXmMU2SMDA8Ru48f/EuXFvI2avy+dsLVgGE/sDGs5/S+PQV69ixrXxOwf/FiCPNRl5GyoTixo6hUUpz0ias0RZKcuDzB/jGIwe5+nvP84/37gLgucPd1K3M571nVmIReHD34rJSoh2YF2tmCsp/BrgF+HaEcwq4NC4SaRacuTSGnI5N5Tnc95FzAaMvV7DFSlChFGfbWVOcxSXri+cn7CKhMn88dXh0zM/A8NhEl5ddK5RkwOsL8MGfv8aLR3vZVJ7No/s7+NUrzRzqcPKFqzdQnG3n3NUFPLjrJJ9eRH3oQrVli8XlpZS6RUQswJeUUpdM2rQySSIG5tAYMhoq8zNC3947hzykp1iXXGrwbKzISw8F5cNrUIJkaQslKahv7uPFo7188ZoN/N/Hz2dDaRZf/uM+wHDjArz9tHKaeoc50rl43F59p5C5GQtmdJorpQLAtxZIFk2C6J9DY8hoqMrPCM2b7xwapSR7YYurFoIVeRmc7B9BKTWhSj5IphlD0fPpljbBzMXLNpaQYrXw9XcY1Qql2XbWlRiFvcG6qv1tg4kRMgL97rl1v4gV0URhHxeRd8aq9kSz+Ogfnr/LK5yq/AzaBkbx+QN0DXkoDvvmnixU5Wfg8QVo7R8ZL2qc5PLyBRQenx4DvJSZbH1uX5nHv15byz9duT70JWlVYSapNgsH2oYSJudkgvN6FtpCicYP8RkgE/CLyAhGU0ellMqOq2SaBcHnD+Ac9cVUoVTmZeAPKNoHR+l0jnLaioVrn71QnL0qH4AXjvbgHDUCoCU5E11eYGTb2FOsCy+gJiZ0DnnISLWG2ukAocSTIDarMcDqYMfiUSj9w16sFiHbvrCu5mjShrOUUhalVIpSKtvc18okSRgYMbNBYpheGCz8a+4dNlxeYfNTkoU1xQ5Ks+0839BNx6DxoRMeJ3LoFvZJQZdzYjr4dNSWZXOwPfJoaDDqVj5175uh+qx40+ceIy8jdcFdzdE0hxQRuUlE/tXcrxSRs+IvmmYheMhMdyyO4Yd+lVkJv79tkNGxQFR/kEsNEeEt6wp5oaGHtoERSrLtE/54HWnBIVtaoSxluoY8EwbKTcfGsiz63N5QIe9kvvPEEf64q41e18I0Gel3exe8BgWii6H8N0b7+veZ+y6M0b2aJc5PXzjOv/3pAJduKOaSDbFL5y3NtpNiFV5v6geMKvpk5MK1RQyN+njhaE+ohX+QzDTDzaXbryxtorVQNpYZTptIcZTjPW5eONoDjGdfhdPSO0zbwNQJoPOhL8Zx0WiJRqGcrZT6OOZQLaVUP7DwkmpiyrOHu/jqQwe4alMp/3PTdtJssfPzWy1CRW46O5uN4Z7JaKEAXLCmEBHDCimd9DNmmRaK7ji8dFFK0Tnkicplu7HcVCjtUxXKb15tDr0PBsvD+eS9b/L53+2Zh6RTMSyUxalQxkTEynhzyCJAp64sceqb+rFahO/esG1eLVemozI/I9QjLFkVSl5mKqdVGO1kwgPyEBZD0QplyeL0+BgZ80dlYWfbU1iRl87BSQpldMzP/TtbWWPODgpWsAdRSnGsyzXluvmSiD5eEJ1C+T7wB6BYRL4OvAD8v7hKpYk7jT0uqvIz4paBVBXWNnuyOyiZeMu6IoApFkowK8ipFcqSJViDEu0Xoo1l2VMslEf2tTMwPMYnLlkDTHV5DQyP4fT46HF5Q12/50sgoOgfHlvwGhSILsvr1xjdhb+B0c/reqXU/bF4uIhcJSKHReSoiNwa4XyaiNxnnn9VRKrDzn3BPH5YRK6MhTzLiWNdbmri2PU3qFCy7DYyUpOrSj6cYLX0ykkt+bN0lteSJziBNJqgPBiZXk09bka8/tCx377eSnVBBldvKQXGCw6DNPeN94OLtsGkUoqW3mEOdzgjnneO+vAH1OK0UMz5J8eVUj8C9gFXiMi8CwtMN9qPgKuBWuBGEamdtOxDQL9Sag3wHeCb5rW1GCODNwFXAf9t3k8TBf6A4nivm5qi+CmUYOpwsrq7gmxfmceDnzifi9dNTGpIs1mwWgSXZ2yaKzWLnU7n1JY6M7GxLJuAgsOdxgd9t9PDq8d7uW5bBWk2I628f5IV0tzrDr1viEKh/Lb+BGd+/Une8p/PcM33n6d9cGowvy/Ux2txZnn9DqOocQ1wF7AK+E0Mnn0WcFQp1aiU8gL3AjsmrdkB/MJ8/wBwmVmxvwO4VynlUUodB46a99NEQdvACF5fgNVFjrg9oyqkUJLX3RXktBW5WCwT8/1FBEeaDbfHP81VmsXOXF1em8zA/ItmRtej+zsIKLh2SxlgxNwmWyjBJqqpNsusFoo/oPjPxw5T6Ejjc1euxx9QPLqvY8q6YOA/lv35oiUahRJQSvkwZqJ8Tyn1aaAsBs+uAE6E7beaxyKuMWUYBAqivFYzDce6jV/cmjgqlJCFkpXcFspMONL01MalTKQq+ZmozM/gwrWF/OzF44x4/fx5Txtrih2hnl95man0DU+0WJt7hynOSmNtsWNWhfLq8V66nR4+cekaPn7JGtaXZPHw3vYp6xLVxwuiz/K6EXg/8JB5LBZSZtF3AAAgAElEQVS2VKQSzsllpNOtieZa4wYit4hIvYjUd3d3z1HE5KSx2zCz4+nyyklPYWNZNlsrk6/tSrRk2W3a5bWEibYGJZxPXraWHpeX7z/dwGvH+7hmS1mo4DU/IyViDKUqP4M1USiUP+1uJyPVymUbSgC4ZksZ9c39oX5jQfoS1LoeolMoH8QobPy6Uuq4iKwC/jcGz24FKsP2V2AM8Iq4RkRsQA7QF+W1ACil7lRK1Sml6oqKimIg9tLnWLeLbLuNgjj/wj3yqQu5+bzquD5jMaOHbC1tuoY8c+4gcWZ1PufU5PPjZ49NcHeBaaFEcHlVFWSwpsjByYGRaeuWvL4Aj+xr54raEtJTjXDxNVtKUYopbq/+BDWGhOiyvA4opT6plLrH3D+ulLo9Bs9+HVgrIqtEJBUjyP7gpDUPAjeb798FPK2MZjkPAjeYWWCrgLXAazGQaVnQ2O1mdbEj6VrKLzYy9RjgRYlSKqoU3U7n6Cl1yv7kZWsBJri7wHBBhQflR8f8dAyNUpWfwVpzXdB7MJkXj/YwMDzGdVvLQ8fWlmSxttgxxe3VPzxGqtVCZurC5ynFvqItSsyYyCeAx4CDwG+VUvtF5Csicp257KdAgYgcxeh6fKt57X7gt8AB4FHg40opHf2MksYeFzWF8YufaAz01MbFybNHutn+tSfZ0zow7RqlFF1RVslP5tyaAv7mnJV84pI1E7605WWmMuz1h+bSt/aPoJSRch4sfGzoGk8FHhwZ42O/3snn7t/ND55uINtu48K1E70sV28p47WmPrqc426vfreXvMyUhHxhTJhCAVBKPayUWqeUWq2U+rp57MtKqQfN96NKqXcrpdYopc5SSjWGXft187r1SqlHEvUzLDVcHh+dQ564xk80Bnpq4+Lk5WO9+AOK/37m2LRr5lIlPxkR4avXb+b60yfmCQVjGkErpaXPsEaq8jNZWZCJzSKhOIpSin9+YDeP7+/k6UNdvNEywI5tFVO6WuzYVo4AP3z6aOhYovp4QXTzUDRJRKOZ4bVaK5S4o7O8Fie7WgzL5LEDHRzrdk1In//9G6009Q7z9tOM2Ecs66iCH/J9bi9lOek09xopw1X5GaRYLVQXZoZqUX7+UhOP7e/kS9du5MMX1tDn9kacbbK6yMH7z63mly838Z66SqoKMjjS6aQiNz1mcs+FaRWKiPyJaTKnAJRS1013TrN4Cfpo41mDojGoyEtn2OunfXCEspzE/IFrJuLzB9h7cpC3by3n8f0d/OQvjdz+ztMAY2bJ5x7Ygz+geMmsJSmOYdp7yEIx+3m19A2TkWql0GEcX1Pk4KVjPfzNT1/llcZeLt9YzIfMYV4zZWx9+op1PLSnnS/+YS8BpTjZP8KXrp1cI74wzOTy+hbwbeA4MAL8xNxcGBXzmiVIY7cLi4zPLNHEj+Cs8Z3N/dOuueO5Y3z6vl0LJdKy53Cnk5ExP5dvLObddSv43Rut7GkdYHB4jE/e8ybluXb++uwq6ptjP3ohL8Ootgim9bb0GinDwVjH1VtKKcxKwznq49otZXzr3VujioPkpKfwxWs2sKd1kKNdLn5ycx1X1JbETO65MK2FopR6DkBEvqqUekvYqT+JyF/iLpkmLuxrG2JVYWZM29VrIrOxLJv0FCv1Tf287bRyXB4f773jZT535XouXl9MIKC4+8Xj9Lq83P7OLfr/ZAHYfWIQgG2VuZxemcfv3zjJdT98kYxUK2P+AA989Dy2VOTg8QX48552ynJi6PIKWSiGQmnuG57QT2/Htgp2bDu1+ux3nF5Bl9PDWavyOaMqb/7CniLRxFCKRKQmGBA303R1QccSZMwf4NXG3inBQk18SLFa2FqZE7JQnj7Uxf62Ie56/jgXry/mzRMDdJrtPY50uNiyIieR4i4Ldp3oJy8jJWQZPPu5i3nqYBfPHu7iso0loULc/3zXafzr22pj2tg0N920UNxe/AHFib5hLl4Xm49SEeGjF62Oyb3mQzT/Wp8GnhWRYIZVNfCRuEmkiRt7Tw7i9vo5b3VhokVZNtStzOfHzx3D7fHx6D6jXuDFYz2cHBjhsf3jBWn72wa1QlkAdp0YYGtlbsiVVJxl58azqrjxrKoJ60SEnPTYNle0WS3kpKfQP+zlcIcTjy/AporsmD4j0URT2PgoRuHgp8xtvVLqsXgLpok9Lx/rBeCcmvwES7J82F6dhz+gePV4L88c6ubi9UUoBb/f2coj+9p5y7oistJs7I8wOlYTW5yjYzR0udiWwHZA+Wa1fHCaad3K5PpbnNVCEZEMjKLClUqpvxORtSKyXin10GzXahYXLx/rZUNpFgWO5O8AvFg4oyoPEfjOEw2MjPn5uwtr8IwFuPP5RpyjPj5+8RpGvX72tw0mWtSkZ+/JQZQioQolL8OwUHY291OclcaKvOTK/oumsPFngBejnxcYfbS+FjeJNHHB4/PzelMf564uSLQoy4qc9BTWFWex9+QguRkpnLUqn3dtX4Fz1IdF4IraEmrLsznY7sQfmDZLXxMDdp0w6k8Sb6GMUd/cT111XtK1P4pGoaxWSv0HMAaglBohcrdfzSJmV8sAHl+Ac2u0QllotlcbWTdXbCwhxWrh6i2lZKZaOWtVPgWONDaVZzMy5ud4T+Q+TprYcLDdyYq89ITMCQmSl5HK8R4Xrf0jbE8ydxdEp1C8IpKOWeRoTnD0xFUqTcx56VgvFoGztUJZcM6qNj44gmNgM1Jt/OyDZ/H1d2wBYFO5EYzXbq/40tDpZF1JVkJlyM9MZXQsAIzXKSUT0WR5/RtGA8ZKEfk1cD7wgTjKpIkDzzd0s7kiJ+aZK5rZufa0MjJSrVyyfnxM8Fmrxr+dri1xkGq1sL9t6JTrEDQz4/MHaOx2c9H6xFY8BGtR7CmW0ITHZCKaLK/HMaY1fgC4B6hTSj0bX7E0sWRncx9vtAzwttNiMWhTM1dSrBbeuql0Wn95itXCulIH+9sGGRj28sddJxnzBxZYysXH0OgYB9sjZ7/d8dwxnj3cFfW9mnqH8foDrCtOsIViutu2rsglxZrQ3rxxYdafSESeAs5WSv1ZKfWQUqpHRO5cANk0MeK7TzZQkJnKTeesTLQommnYVGYUQF74zWf41L27eO6wni7642ePce33n+eBna0Tjve5vXzz0UPcP+n4TBzpNNrCry9NrEIJWih11cnn7oLoYiirgM+LyG1hx+riJI8mxtQ39fF8Qw8fuagmplW/mthydk0+o2OBUHHjwIgeHdw5OEpAwece2M09r7WEjj99qIuAgl5X9KHcI51ORBLfFLUq3+ihd8Ga5Gw2Es0nzABwGfB9swPxTfEVSRNLvvtkA4UObZ0sdt5xegUXry9GgNO/+gSuUa1Q+oa9rCtxUJGbzhd+v5cNpVmcXpXH42aHgcnjdGeiodNFVX5GaHxuolhfmsXLX7g0abtPR2OhiFLKp5T6GPA74AWgeJZrZr6hSL6IPCEiDebrFPtPRLaJyMsisl9E9ojIe8PO/VxEjovILnPbNh95kpWBYS8vHO3hpnNWautkkSMi5Gemkplm/D/pOSpGE8XSnHR++L4zyM1I4YdPH2XE6+cvDYY7sNcVvUI50ulkbYLjJ0GSVZlAdArlf4JvlFI/xwjOPz7P594KPKWUWgs8Ze5PZhh4v1JqE3AV8F0RCa9I+pxSapu56f7fEehyGi6BVYV6mNZSIdVmIc1m0ZMeMSyU/IwUMtNsfOj8VTx1qIs7/nKM0bEAp1fl0j/sDRWDDnt9vNkSeUyA1xfgeI97wnx3TXyYVqGISDCn7X7TosgXkXyM+Sj/NM/n7gB+Yb7/BXD95AVKqSNKqQbzfRvQhe5yPCd6TIVSpFutLCmy7DacWqHQ7x4LBbHff141WWk2vvdUA1l2G9duKSOgDCsc4L7XT/DOH79E19DolPs09brxBVTCa1CWAzNZKL8xX3cC9ebrzrD9+VCilGoHMF9ndKGJyFlAKhA+BPrrpivsOyKiPzEj0G0GLQuz9D/PUiLLnoJrmbu8vL4ALo8vlGabk57C+89biVJwyfri0GjeYBzlRN8IAWX065pMMMNrrbZQ4s60CkUp9TbzdZVSqsZ8DW41s91YRJ4UkX0Rth1zEVBEyoBfAR9USgWT878AbADOBPKBz89w/S0iUi8i9d3dyysVs8f0MRdqC2VJ4UizLXuXV9DyyA0bffu356+itiybG86spMA8Hvwd7zQtk30np9atHOlwYlkEGV7LgZlmyp8x04VKqTdmOX/5DPfuFJEypVS7qTAiViiZbrc/A19SSr0Sdu92861HRH7GDC44pdSdwJ0AdXV1y6r7Xo/Lg9UiocE+mqWBI82Gc5lneQXH5OaH9d0qcKTx8KcuBOBwh2F1BC2UjqBCidC+Zl/bENUFmdhT9ETMeDNT6s+3ZzingEvn8dwHgZuB283XP05eICKpwB+AXyql7p90LqiMBCP+omfcR6DH6aHQkYrFont5LiUcdhsn+oYTLUZCCSqKvMzIX4byTQul1224dTsGgxbKuEIJBBTfeOQgTx/q4kMXrIqnuBqTmWbKXxLH594O/FZEPgS0AO8GEJE64KNKqQ8D7wHeAhSIyAfM6z5gZnT9WkSKMLoe7wI+GkdZlyw9Lo92dy1BsrTLi363YaHlZ0buDJyXkYKIkTocCCi6nKNkplppHxylx+WhIDOVz96/mz+8eZKbz13JF6/ZuJDiL1uiKk4Qkc1ALWAPHlNK/fJUH6qU6sUolpx8vB74sPn+f4H/neb6+VhHy4Yel1crlCVIll0rlEgur3BsVgu56Sn0uj30DXsZ8ysu21DEo/s72N82RF5GCn948yR/f/Fq/vnK9Uk3d2SxEs3ExtuAizEUysPA1RjFjaesUDQLQ4/Lo1MllyAOuw3XqA+l1LL9IOw3XV4zzS4pcKTR5/aG3F2Xbizm0f0d7Ds5SGv/MPYUC39/8epl+2+YCKIpbHwXhjXRoZT6ILAV0F97FzlKKXpdXgqzEjdMSHNqONJS8AVUaG7GcqTP7SUrzUaqbfqPqPzMVHpc3lCG19piBysLMnilsZc/7mrj7aeVk23XCSkLSTQKZcRM1/WZWVddwKxpw5rEMjTiw+sP6KLGJYjDbrZf8SzfTK/+YW+oqHE6Ch2p9Lm9tJsWSmmOnc3lOTzf0MOw18+NZ1cthKiaMKJRKPVmy5OfYBQ1vgG8FlepNPMmVNSoFcqSI8vs57Wcixv73LMrlPzMVHpdHjqHRrGI0RFic4XRrXl9SRanJ3B2/HJl1hiK2RQS4H9E5FEgWym1J75iaeZLj1YoS5Ys00KZHJg/2uWkvqmfG85K/m/e/cPeWa3rgsw0BkbGODkwQqEjDZvVwhZTodxwVqWOnSSAaLO8TgOqg+tFZI1S6vdxlEszT0IKRcdQlhyOaSyUn77QxD2vtXBFbQkFSf5Fod89NmtCSYEjFaXgULuT0hwjAfW81QV874ZtXL1ZTydNBNFked0NnAbsB4JRQgVohbKICTaG1BbK0iMYQxkanWqhALze1M9Vm0sXXK6FpM/tnTZlOEhBpvG73dDl5OL1RjtAi0XYsa0i7vJpIhONhXKOUqo27pJoYkqPy4tFIG+WP0rN4iMrzchMCnd5KaVo6HIB8HpTX1IrlNExPyNj/qhiKABjfkVptn3GtZqFIZqg/MsiohXKEqPH5SE/Mw2rbruy5AhaKOFTG3vdXgaGjf3XjvclRK6Foj9Y1DiLQilwjJ8Purw0iSUaC+UXGEqlA/BgtDtRSqnT4iqZZl4YbVe0dbIUCcVQwiyUhk7DOtlWmcue1gFcHl9oXbIR6uM1q8tr/HyJtlAWBdH8Rt4N/A2wl/EYimaR0+3yUqTnoCxJglMbw4dsBeMn7zu7il0nBtjZ3M9F65Jz3txsfbyC5GakIgJKoV1ei4RoXF4tSqkHlVLHlVLNwS3ukmnmhdFpWCuUpUqW2X4lSEOXC0eajWu2lGG1CK9H6fYKBBS/rT+Bx+ePl6gx49F9HZwcGAn18crLmLnK3WqRUOC+NEf/ri8GorFQDonIb4A/Ybi8ANBpw4sXpZR2eS1xjJkoE11ea4odONJsbC7P5rWm6BTK6019/PMDe0izWRZ19tOw18ff/3onF68rCmVszRaUB7O40e3VLq9FQjQKJR1Dkbw17JhOG17EuDw+PL6AtlCWMI5JHYcbulxcst5wcZ1Znc8vX2nG4/OTZpt5aFQwM+yo+bpYaex2oxQ8c7ibFKvhOIlmMFyBI5W2AStZumfXomBGhSIiVmCPUuo7CySPJgbo0b9Ln6y08bnyA8Neelye0Ez089YUcNcLx3nyQBfXnjZzAV9QkQSD+ouVxh43ABaBxw90kpOegs06u0d+VWEmI97F785bLsz4P6aU8gPXLZAsmhgxXiWvFcpSxWG3hYLyQaWwttioHL9oXTFrih1898kj+AMzT7U+1m1aKN2LW6Ec63IhAu8/txqYPSAf5F/fVssv//bsOEqmmQvRBOVfEpEfisiFInJGcJvPQ0UkX0SeEJEG8zVvmnV+Edllbg+GHV8lIq+a199njgvWmOw+MQDA6qLMBEuiOVWMqY1GtlPQbbWm2LBQrBbhHy9fS0OXi4f2tM14n6AyaupxM+aPPknT6wsQmEVZxZJj3S4q8zL42MWrSbVZZg3IB8lItZET5VpN/IlGoZwHbAK+gjFn/tvAt+b53FuBp5RSa4GnzP1IjCiltplbuKX0TeA75vX9wIfmKU9S8czhLtYWO1iRl5FoUTSniMM+HpRv6HSRnmKlIjc9dP6azWVsKM3ie0824JtGUbg8PtoHR1lT7MAXUDT3uqN+/nvueJkP/vx1vL6FqRRo7HazuiiT4mw7/37dJm4+r3pBnquJLbMqFKXUJRG2+Y7g3YFRMIn5en20F4rRQvRS4IFTuT7ZcXl8vHa8j0s3FCdaFM08cKSNT2080ulkdXEmlrCuBxaL8I+Xr6Oxx83jBzoj3qPRdHNdbbZpiTaOopTiYPsQzx3p5tbf70Gp+FoqgYCiscdFTZFhgd14VtWizkjTTM+sCkVEckTkv0Sk3ty+LSI583xuiVKqHcB8ne7Tz24+8xURCSqNAmBAKRVMgWkFpv3tE5FbgrJ3d3fPU+zFzwsNPYz5VSj1UrM0ybIbUxuHvX52nxjgtBVTZ3tcvrGYFKuw7+RgxHsE3V1vrTUVSpSZXoMjY3h8AWqKMvn9Gyf5wdNHI65ze3wxcYu1DY4wOhZgtalQNEuXaFxedwNO4D3mNgT8bLaLRORJEdkXYdsxB/mqlFJ1wPuA74rIaozWL5OZ9rdaKXWnUqpOKVVXVJSclcXhPHOoiyy7jbrqiGEpzRIh2M/rjZZ+nB4f26um/n/arBYq8zJo7h2OeI+jXS5sFmFDWRYVuelRpw53mCN1P3PFOi7fWMLdLx4PWSmjY36++Ie9XPrtZ9l022Pc/uihU/nxJtDYbbjidMxv6RNNHcpqpdQ7w/b/XUR2zXaRUury6c6JSKeIlCml2kWkDGOscKR7tJmvjSLyLHA68DsgV0RsppWyApg5MrlMUErxzOEu3rK2KJTLr1maBKc2PnvYsKqn+4KwsiCD4z2RYyNHu1ysLMggxWphbYkjagulc8jIEizNtnPR+iKePNhJ++Ao5bnpvHi0h9+82sIFawopy7Fz1/ONXLe1PDQp8VQIZqLVaAtlyRPVTHkRuSC4IyLnAyPzfO6DwM3m+5uBP05eICJ5IpJmvi8EzgcOKOOr0jPAu2a6fjmyv22ILqeHi9cnvyWW7DhCCqWLQkcaVfmREyxWFmTS3OuOGOc41u0KZYatKXLQ2O2aNc0YoNOc0V6Sbae2LBswfrcA9rQOYhG442+2899/vZ38zFT+5f/2RXXf6TjW7SLbbtOdHZKAaBTKR4EfiUiTiDQDPzSPzYfbgStEpAG4wtxHROpE5C5zzUaMefa7MRTI7UqpA+a5zwOfEZGjGDGVn85TnqTg+YYeAB0/SQKCLq9j3W7qVuZNO852VWEmbq+fbpdnwvExf4Dm3uFQXGJtiQOPL0Brf2T3WDhBl1dxdhobSrMQgQMhhTLAmmIHmWk2ctJT+NK1tew+McA9r7Wc8s/a2O2mpsihR/YmAdHMlN8NbBWRbHN/aL4PVUr1ApdFOF4PfNh8/xKwZZrrG4Gz5itHsnGoY4iK3HTdZTgJCG9NP1M8bGWBYbk09w5TnDXez6q5140voMYtFPPVcIPNHKvoGBolPzOVNJuVNJuhtA60D6KUYk/rIJeEZRDu2FbOr15p5ucvNXHTOSvn/oNiWCgXrNFWdTIQTZZXmoi8D/gE8I8i8mUR+XL8RdPMlaNdLlYXaz90MpAd1ptq+8rpFUq1qRyaJsVRjk4qhlxTZFTZH4kidbhzcHRCs8XasmwOtA/RNjhKr9vL1hXj8RIR4erNpRztctE2MHdPuMvjo3PIw+piHZBPBqJxef0Ro27EB7jDNs0iIhBQhs9cBzaTgqDLK81mYVP59AHvFXnp2CxC06SixfqmflKsElIoORkpVOSms68tcopxOB1Do5Rmj1u5teXZnOgb4YUGI0Fgy6QU5uBclr8cmXta/qF2w+GhU4aTg2iyvFYopa6KuySaeXFywMjlX6MtlKQgM83oIry1MpdU2/Tf+2xWCyvy0mkKSx1WSvH4gU7OW11IRur4n/i2qlx2tQzM+uzOoVG2hGVtBRXava+fIMUqbCzLmrB+TbGDshw7zx3p5oazqqL7AU2eONBJilU4p6ZgTtdpFifR9vKKGMvQLB4muzg0S5s0m5XyHHtUGXvBTK8ghzqctPQNc+Wm0gnrTq/M5eTACF1m0D0SXl+AHpd3issL4M2WAdaXZk1pmS8ivGVtES8c7Zm2DUwklFI8vK+d81YXkhNFq3rN4icahXIBsFNEDovIHhHZKyJ74i2YZm5ohZJ8PPXZi/nIW1bPum5VYSZNPcOh1OHH9ncgAlfUlkxYd3qV4ap688T0VkowW6w0Z1yhFGWlhRI9IlXsA7xlXRHOUR+7W2e3gILsbxviRN8I12wpnX2xZkkQjUK5GliLMWDr7cDbzFfNIuJol4v8zNSo235rFj/pqVasltlTaVcWZODy+Oh1G3NwHtvfyfaqvCnZfpvKc7BZhF0zKJQOswZl8oz2oJUSHpAP54I1hVgEnjvSM6u8QR7Z147VIlxRqxVKshBNc8jmSNtCCKeJnqM6IL9sCc/0OtE3zMH2oSnuLgB7ipXa8mzebOmf9l6dQ+NFjeFsKjcUypaKyBZKTkYKWytzeS7KwLxSikf2dXBOTb7+EpRE6P4cSYBSSqcML2OqCw2FcrzHzQM7WwEiKhSAbZW57GkdnLayPWSh5ExUKO/cvoIPX7CK9aVZkS4D4LzVBextHcDjm32CYkOXi8ZuN1dtnnnipGZpoRVKEtDj8jI4MsZarVCWJRW56VgtwlcfOsD3nmrg3JoCqgoit2o5vSqXYa+fI53OiOc7h0ZJtU4dcLW6yMGX3lY7owtubXEWAQUt0zSrDOIPKL7x8EFsFuHKTSUzrtUsLaJJG9YscnRAfnmTarNQW5ZN++AoX9mxnhvOnD51d1ulUST5fEM3f3jzJAPDXv7jXVtD5zuGRinOTjulNig1ZrfgY91u1pZMb8l84+GDPHO4m69dv3lCdb9m6aMVyhKj1+XhPXe8zLqSLHZsK+eSDcWheeFaoSxf7vvIOVhEsKdYZ1xXXZBBbkYK/+/h8bbzX9mxOXRdx+DolIB8tKwqDCqU6avxf1t/grteOM7N56485VYtmsWLVihLjBeP9XKs202X08Mj+zooyEylwJFKZqqVshz9bW+5El7AOBMiwrvOWMHBjiE2lmZz1wvH6RgcDcVhupweas0A/FzJsqdQkp0Wmm8ymQNtQ/zr/+3j/DUF/Ovbak/pGZrFjY6hxIj760/w9KHIo1hjyRvN/WSkWnn9Xy7n5x88k+0r8zja5WJTeY7u1qqJii+9rZZff/icUJPHYHdhpdS8LBSAmkJHRAvFOTrGx3/zBjnpKXzvhtOx6Xk9SYm2UKLgmcNdOEd9XLe1fNo1P3j6KGU5di7dEN8gY31zH9sqc7GnWLl4fTEXry+ma2hU/4Fq5kwwNTiY2TU06mNkzE9J9ql3q15dnMmDu9pQSk34gnPbg/tp7nVzz9+dQ6FDd8NOVvSnUBT8+pUWvv9Uw4xrel2eKQ36Yo3b4+Ngu3NK99nibLvO5dfMmWBqcLupUIKzUlbkRc4Qi4aaQgdDo+NFlmC0c3loTzt/ffZKztY9u5IarVCiYFN5No3dLka8kfPrR7x+3F4/nUMehr2+uMmx68QA/oCasZ25RhMtjjQbWXZbqJjxRJ+hUKabDhkNoUyvsHHDhzuceH0B3QByGZAQhSIi+SLyhIg0mK9TPiFF5BIR2RW2jYrI9ea5n4vI8bBz2+Ipb215NgFlDLCKRK97fFpeU8/sE/FOlZ3N/YjAGVqhaGJEabad9kFjjkmLqVAq56FQgm3oG8Pms+w6YVTmb6089bnzmqVBoiyUW4GnlFJrgafM/QkopZ5RSm1TSm0DLgWGgcfDlnwueF4ptSuewgb7GB1oj6xQelzj5n083V71zf2sL8maMHxJo5kPpTl2OoaML0QtfcPkpKfMq/NvRW46aTYLjWGB+V0nBil0pFGRmz5veTWLm0QplB3AL8z3vwCun2X9u4BHlFLx+/o/Ayvy0sm220JztSfTGzbP+3hPfBSKP6B4s7lfu7s0MaU0205HyEIZmZe7C8BiEVYVZnIsLHV4d+sA2yp1FuJyIFEKpUQp1Q5gvhbPsv4G4J5Jx75uttP/johMmzYiIreISL2I1Hd3z32inHkPasuzp7VQek0LxWaRKaNYY8WRTidOj2/G+eIazVwpy7HT7fTg8wc40Tc8b4UChtsraKEMjY5xrNvF1mna3muSizHDIzIAAA/rSURBVLgpFBF5UkT2Rdh2zPE+ZcAW4LGww18ANgBnAvnA56e7Xil1p1KqTilVV1Q0+7Ci6agty+FQuzNiU70eM4ayqTw7bi6vP+1uA6BuZX5c7q9ZnpTk2Ako6HR6aO0fnlf8JEhNUSYn+kfw+PzsbR1EKWNapCb5iVsdilLq8unOiUiniJQppdpNhdE1w63eA/xBKTUWdu92861HRH4G/FNMhJ6B2vJsRsb8HO9xT2lx0uvykplqZUNpNk8dmulHOTWae93c9fxx3nF6RUz+4DWaIMHuCrtaBhjzq5hYKGuKHfgDipeO9oas+ukGc2mSi0S5vB4Ebjbf3wz8cYa1NzLJ3WUqIcRwyl4P7IuDjBOYKTDf4/JQ4EijujCTHpcH5+jYlDXz4Wt/PojNKtx69YaY3lejCRY3vna8F5hfynCQK2pLWFPs4LP37+bJg53UFGXqEb/LhEQplNuBK0SkAbjC3EdE6kTkruAiEakGKoHnJl3/axHZC+wFCoGvxVvgNcUOUqwSMTDf6/JS4EhlVaHxx9hstu+ebubEXPjLkW6eONDJP1y6dsrQI41mvpTlGJlXrx7vA2KjUDJSbdzxN9vx+gK82TLANm2dLBsSolCUUr1KqcuUUmvN1z7zeL1S6sNh65qUUhVKqcCk6y9VSm1RSm1WSt2klJq+vWmMSLVZWFeSNb2Fkpk2ZdDRptse5cfPHpuXYrmv/gTFWWn87QXVp3wPjWY68jJSSLVZONzpxGoRynJj86VldZGDb73baItfV63jfssFXSk/B2rLsjnQNohSExVEr9tLoSOVlfmGQnmzZYCv//kAqVYL33z0EO/6n5foD2tFMRcOtQ+xrTKXNNvMbck1mlNBRCjNtqMUlOfaSYlhT7irNpfy9Gcv4t11K2J2T83iRiuUOVBbnk2Py0u3c7zuJBBQ9Lm9FDrSSDdbyP/i5SYGR8a47yPn8t33buPNlgF+/+bJOT9v1EwC2FB2au3ENZpoCHYXjoW7azI1RY6YKinN4kb/T8+BYGB+f5jba2BkDH9AUeAwmjNWF2TiDyjef241G8uyuf70Cipy03mjpX/Oz2vodBFQsGGGOd4azXwJNomMh0LRLC+0QpkDG83BQ+GB+WCVfIHZkntzRTZFWWl8+vJ1oTVnrMzjjea5K5SDZu8wrVA08SSYOqxT0jXzRSuUOZBtT6EqP2OCQgn28So028d/7soNPPXZi8jJGE+T3F6VS/vgKG0DIxHvOzDs5fMP7OGpg50T4jOHO5zYUyysLMiMx4+j0QDjqcPaQtHMF61Q5kht2cQWLMFOw0ELJdVmmdK8MdgdeDq319OHuriv/gQf+kU9b/vBC6GJd4c6hlhfkoXVonsgaeJHcBb82mJtCWvmh1Yoc6TWbK/i8hhzT3qcQYUy/YCrjWXZ2FMs7JzG7XW4w0mq1cJ/vPM0WnqH+a8njqCU4mC7kw2lOiCviS8Xry/ikU9dyHrtWtXME61Q5khtWTZKwWEzvtHr9mIRyMuYXqGkWC1sXZE7bRzlUIeT1cUO3nNmJe+uq+Tx/R0c6nDS5/ayoUz/kWvii4iwUWcSamKAVihzpHZSYL7H5SU/M3VWt9T2lXnsbxtidGzq1Mcjnc5Q4P19Z1cy5ld87c8HAPS3Ro1Gs2TQCmWOlOXYyctIYb+pUHrNKvnZOKMqD19Asad1cMLxweEx2gdHQ4pjTXEWZ1Xn8+JRo7eSdnlpNJqlglYoc2TybJRet3fG+EmQYGB+chzlcKcTgPUl45bI+86uAqAkO438zNnvrdFoNIsBrVBOgdqybA51OPH5A6FOw7ORn5nK2mIHLx3rmXA8GIsJd21dtbmUvIyUUCGlRqPRLAXiNg8lmaktz8brC/CNRw7R7fRQGIWFAnDRuiJ++XIzw14fGanGP/3hTidZdluouAzAnmLlVx86W8+O12g0SwptoZwCl28s4bINxfz8pSaGvX6Ks6Lr0HrR+iK8/gCvNvaFjh3uMALyk+dtb67IoapAF5ppNJqlg7ZQToEsewo//cCZ9Lg8vHi0h4vWRTda+MzqfOwpFp470s0lG4pRSnGow8l1W8vjLLFGo9HEn4RYKCLybhHZLyIBEambYd1VInJYRI6KyK1hx1eJyKsi0iAi94lIQiLXhY40dmyrIHeGGpRw7P+/vTuPsauswzj+fWgLtAUptALShQFSCqVhc8ImIkEUWpGCwaQEQwUiMUgEEQWsMRBNlEismkC1ASkSAkhlKbssDRCU2o2lWAoDbWFoKwVZSmWVn3+878Dp9N7O0Dkz99z2+SSTmfOec+888+ae+5uz3Pcd0I9Ddx/KQ8+uBmDVW++y5t0PPVaXmW0SGnXKaxHwDeDhehtI6gdcDowHxgInSxqbV18KTI2I0cDrwBm9G7c8X9rzsyx9dS3LX1vLM6vyHV6+NdjMNgGNmrFxcUQs6WKzg4C2iHghIt4HbgAm5nnkjwJm5u2uIc0r3xSOHLMjAFc/uoxps58HYM+dtmlkJDOzUlT5Gspw4KXCcjtwMDAUeCMiPiy0D+/jbButZdhgdh06iBl/X8Z2AwfwixPGdfuUmZlZlfVaQZF0P7BzjVVTIuK27jxFjbbYQHu9HGcCZwKMGjWqG7+29/1kwt48u2oNpx7WwnYDfWuwmW0aeq2gRMTRPXyKdmBkYXkEsAJ4FRgiqX8+Sulor5djOjAdoLW1tW7h6UvH7LMzx+xTq9aamTWvKn8OZS4wOt/RtSUwCZgVaQaq2cBJebvJQHeOeMzMrBc16rbhEyW1A4cCd0q6N7fvIukugHz0cTZwL7AY+EtEPJ2f4gLgPEltpGsqV/X132BmZutSccrZTV1ra2vMmzev0THMzJqKpPkRUfczgx2qfMrLzMyaiAuKmZmVwgXFzMxK4YJiZmalcEExM7NSbFZ3eUlaDSzfyIcPI32oslk0W15ovszNlheaL3Oz5YXmy9ydvLtGRJfzdGxWBaUnJM3rzm1zVdFseaH5MjdbXmi+zM2WF5ovc5l5fcrLzMxK4YJiZmalcEHpvumNDvApNVteaL7MzZYXmi9zs+WF5stcWl5fQzEzs1L4CMXMzErhgtINko6VtERSm6QLG52nM0kjJc2WtFjS05LOye07SLpP0nP5+/aNzlokqZ+khZLuyMu7SZqT896Ypy2oDElDJM2U9Ezu60Or3MeSfpBfD4skXS9p66r1saQ/SXpF0qJCW80+VfL7vB8+KenAiuT9dX5NPCnpFklDCusuynmXSDqmr/PWy1xYd76kkDQsL/eoj11QuiCpH3A5MB4YC5wsaWxjU63nQ+CHEbE3cAjwvZzxQuCBiBgNPJCXq+Qc0tQEHS4Fpua8rwNnNCRVfb8D7omIvYD9SNkr2ceShgPfB1ojYhzQjzSnUNX6eAZwbKe2en06Hhidv84EpvVRxqIZrJ/3PmBcROwLPAtcBJD3wUnAPvkxV+T3k742g/UzI2kk8BXgxUJzj/rYBaVrBwFtEfFCRLwP3ABMbHCmdUTEyohYkH9eQ3qjG07KeU3e7BrghMYkXJ+kEcDXgCvzsoCjgJl5k6rl/QxwBHnunYh4PyLeoMJ9TJqRdaCk/sAgYCUV6+OIeBj4T6fmen06EfhzJI+RZm79XN8kTWrljYi/5fmbAB4jzSILKe8NEfFeRCwF2kjvJ32qTh8DTAV+zLpTqPeoj11QujYceKmw3J7bKklSC3AAMAfYKSJWQio6wI6NS7ae35JezB/l5aHAG4Uds2r9vDuwGrg6n6a7UtJgKtrHEfEycBnpv8+VwJvAfKrdxx3q9Wkz7IunA3fnnyubV9LxwMsR8USnVT3K7ILSNdVoq+StcZK2Af4KnBsRbzU6Tz2SjgNeiYj5xeYam1apn/sDBwLTIuIAYC0VOb1VS77uMBHYDdgFGEw6ndFZlfq4K5V+jUiaQjr9fF1HU43NGp5X0iBgCvCzWqtrtHU7swtK19qBkYXlEcCKBmWpS9IAUjG5LiJuzs3/7jhczd9faVS+Tr4AHC9pGekU4lGkI5Yh+fQMVK+f24H2iJiTl2eSCkxV+/hoYGlErI6ID4CbgcOodh93qNenld0XJU0GjgNOiU8+i1HVvHuQ/tF4Iu+DI4AFknamh5ldULo2Fxid747ZknSRbVaDM60jX3+4ClgcEb8prJoFTM4/TwZu6+tstUTERRExIiJaSP35YEScAswGTsqbVSYvQESsAl6SNCY3fRn4FxXtY9KprkMkDcqvj468le3jgnp9Ogs4Nd+JdAjwZsepsUaSdCxwAXB8RPy3sGoWMEnSVpJ2I13o/mcjMhZFxFMRsWNEtOR9sB04ML/Ge9bHEeGvLr6ACaS7N54HpjQ6T418h5MOS58EHs9fE0jXJR4Ansvfd2h01hrZjwTuyD/vTtrh2oCbgK0ana9T1v2BebmfbwW2r3IfA5cAzwCLgGuBrarWx8D1pGs8H+Q3tjPq9SnpdMzleT98inQHWxXytpGuO3Tse38obD8l510CjK9KH3davwwYVkYf+5PyZmZWCp/yMjOzUrigmJlZKVxQzMysFC4oZmZWChcUMzMrhQuKWQ15ZOGzCsu7SJq5occ0iqS7iiPcdmP7iyWd35uZbPPkgmJW2xDg44ISESsi4qQNbN/n8ofPtoiICZEGqjRrKBcUs9p+Bewh6fE830VLx3wSkr4t6VZJt0taKulsSeflQSMfk7RD3m4PSfdImi/pEUl7df4l+WjhWkkPKs3/8Z3Cuh9Jmpvnpbgkt7UozcVyBbAAGClpWWE+i/OU5j9ZJOncwnNNyXNy3A+MwawX9O96E7PN0oWkOS72h49HcS4aRxrVeWvSJ6UviIgDJE0FTiWNTTYd+G5EPCfpYOAK0rhlne1LmsdmMLBQ0p35+UeThjsXMEvSEaQhVcYAp0XEWTkb+fvngdOAg/Nj5kh6iPSP46Sctz+pEBUH5jQrhQuK2caZHWnumTWS3gRuz+1PAfvmkZ8PA27qeMMnDX1Sy20R8Q7wjqTZpCJyOPBVYGHeZhtSgXkRWB5prorODgduiYi1AJJuBr5IKii3RB5nSlKlxqKzTYcLitnGea/w80eF5Y9I+9UWpLlH9u/Gc3Ue/yhIRxi/jIg/FlfkI6W1dZ6n1tDj9X6HWel8DcWstjXAthv74Ejz0SyV9E34+AL6fnU2n6g03/tQ0mCZc4F7gdPzkQ6ShkvqavKuh4ET8gjDg4ETgUdy+4mSBkraFvj6xv5dZhviIxSzGiLiNUmP5gvxd5NGYP20TgGmSfopMIA090vnGfIgjf57JzAK+HlErABWSNob+Ec+ZfY28C3gfxvIvEDSDD4ZIv3KiFgIIOlG0ki4y0lFxqx0Hm3YrIEkXQy8HRGXNTqLWU/5lJeZmZXCRyhmZlYKH6GYmVkpXFDMzKwULihmZlYKFxQzMyuFC4qZmZXCBcXMzErxf1iE7lorprHGAAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.2--Cutting-our-time-series-into-sequences">1.2  Cutting our time series into sequences<a class="anchor-link" href="#1.2--Cutting-our-time-series-into-sequences">&#182;</a></h2><p>Remember, our time series is a sequence of numbers that we can represent in general mathematically as</p>
<p>$$s_{0},s_{1},s_{2},...,s_{P}$$</p>
<p>where $s_{p}$ is the numerical value of the time series at time period $p$ and where $P$ is the total length of the series.  In order to apply our RNN we treat the time series prediction problem as a regression problem, and so need to use a sliding window to construct a set of associated input/output pairs to regress on.  This process is animated in the gif below.</p>
<p><img src="images/timeseries_windowing_training.gif" width=600 height=600/></p>
<p>For example - using a window of size T = 5 (as illustrated in the gif above) we produce a set of input/output pairs like the one shown in the table below</p>
<p>$$\begin{array}{c|c}
\text{Input} &amp; \text{Output}\\
\hline \color{CornflowerBlue} {\langle s_{1},s_{2},s_{3},s_{4},s_{5}\rangle} &amp; \color{Goldenrod}{ s_{6}} \\
\ \color{CornflowerBlue} {\langle s_{2},s_{3},s_{4},s_{5},s_{6} \rangle } &amp; \color{Goldenrod} {s_{7} } \\
\color{CornflowerBlue}  {\vdots} &amp; \color{Goldenrod} {\vdots}\\
\color{CornflowerBlue} { \langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \rangle } &amp; \color{Goldenrod} {s_{P}}
\end{array}$$</p>
<p>Notice here that each input is a sequence (or vector) of length 5 (and in general has length equal to the window size T) while each corresponding output is a scalar value.  Notice also how given a time series of length P and window size T = 5 as shown above, we created P - 5  input/output pairs.  More generally, for a window size T we create P - T such pairs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now its time for you to window the input time series as described above!</p>
<p><a id='TODO_1'></a></p>
<p><strong>TODO:</strong> Implement the function called <strong>window_transform_series</strong> in my_answers.py so that it runs a sliding window along the input series and creates associated input/output pairs.    Note that this function should input a) the series and b) the window length, and return the input/output subsequences.  Make sure to format returned input/output as generally shown in table above (where window_size = 5), and make sure your returned input is a numpy array.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can test your function on the list of odd numbers given below</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">odd_nums</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">13</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here is a hard-coded solution for odd_nums.  You can compare its results with what you get from your <strong>window_transform_series</strong> implementation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># run a window of size 2 over the odd number sequence and display the results</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">odd_nums</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">odd_nums</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">odd_nums</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span>
<span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">odd_nums</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
<span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">odd_nums</span><span class="p">[</span><span class="mi">4</span><span class="p">:</span><span class="mi">6</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">odd_nums</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span> <span class="c1">#optional</span>

<span class="k">assert</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;ndarray&#39;</span><span class="p">)</span>
<span class="k">assert</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;ndarray&#39;</span><span class="p">)</span>
<span class="k">assert</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="k">assert</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,)])</span>

<span class="c1"># print out input/output pairs --&gt; here input = X, corresponding output = y</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;--- the input X will look like ----&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;--- the associated output y will look like ----&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--- the input X will look like ----
[[ 1  3]
 [ 3  5]
 [ 5  7]
 [ 7  9]
 [ 9 11]]
--- the associated output y will look like ----
[[ 5]
 [ 7]
 [ 9]
 [11]
 [13]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again - you can check that your completed <strong>window_transform_series</strong> function works correctly by trying it on the odd_nums sequence - you should get the above output.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">window_transform_series_nb</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">wSize</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    
    <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span>  <span class="o">=</span> <span class="p">[],[]</span>
    <span class="k">for</span> <span class="n">loc_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="o">-</span> <span class="n">wSize</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="n">loc_</span><span class="p">:</span><span class="n">loc_</span><span class="o">+</span><span class="n">wSize</span><span class="p">])</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">seq</span><span class="p">[</span><span class="n">loc_</span><span class="o">+</span><span class="n">wSize</span><span class="p">]])</span>
        
    <span class="n">inputs</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">wSize</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span>
    
<span class="n">window_transform_series</span><span class="p">(</span><span class="n">odd_nums</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[65]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(array([[ 1.,  3.],
        [ 3.,  5.],
        [ 5.,  7.],
        [ 7.,  9.],
        [ 9., 11.]], dtype=float32), array([[ 5.],
        [ 7.],
        [ 9.],
        [11.],
        [13.]], dtype=float32))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: implement the function window_transform_series in the file my_answers.py</span>
<span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="n">window_transform_series</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With this function in place apply it to the series in the Python cell below.  We use a window_size = 7 for these experiments.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># window the data using your windowing function</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">window_transform_series</span><span class="p">(</span><span class="n">seq</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">,</span><span class="n">wSize</span> <span class="o">=</span> <span class="n">window_size</span><span class="p">)</span>

<span class="c1"># print out input/output pairs --&gt; here input = X, corresponding output = y</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;--- the input X will look like ----&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>

<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;--- the associated output y will look like ----&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">y</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--- the input X will look like ----
[[-0.7006234  -0.8208848  -0.93938303 -0.9471652  -0.68785524 -0.84325904
  -0.8053202 ]]
--- the associated output y will look like ----
[[-0.8205807]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.3--Splitting-into-training-and-testing-sets">1.3  Splitting into training and testing sets<a class="anchor-link" href="#1.3--Splitting-into-training-and-testing-sets">&#182;</a></h2><p>In order to perform proper testing on our dataset we will lop off the last 1/3 of it for validation (or testing).  This is that once we train our model we have something to test it on (like any regression problem!).  This splitting into training/testing sets is done in the cell below.</p>
<p>Note how here we are <strong>not</strong> splitting the dataset <em>randomly</em> as one typically would do when validating a regression model.  This is because our input/output pairs <em>are related temporally</em>.   We don't want to validate our model by training on a random subset of the series and then testing on another random subset, as this simulates the scenario that we receive new points <em>within the timeframe of our training set</em>.</p>
<p>We want to train on one solid chunk of the series (in our case, the first full 2/3 of it), and validate on a later chunk (the last 1/3) as this simulates how we would predict <em>future</em> values of a time series.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split our dataset into training / testing sets</span>
<span class="n">train_test_split</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="mi">3</span><span class="p">)))</span>   <span class="c1"># set the split point</span>

<span class="c1"># partition the training set</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">train_test_split</span><span class="p">,:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">train_test_split</span><span class="p">]</span>

<span class="c1"># keep the last chunk for testing</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_test_split</span><span class="p">:,:]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_test_split</span><span class="p">:]</span>

<span class="c1"># NOTE: to use keras&#39;s RNN LSTM module our input must be reshaped to [samples, window size, stepsize] </span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">window_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">window_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[69]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((88, 7, 1), (88, 1))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='TODO_2'></a></p>
<h2 id="1.4--Build-and-run-an-RNN-regression-model">1.4  Build and run an RNN regression model<a class="anchor-link" href="#1.4--Build-and-run-an-RNN-regression-model">&#182;</a></h2><p>Having created input/output pairs out of our time series and cut this into training/testing sets, we can now begin setting up our RNN.  We use Keras to quickly build a two hidden layer RNN of the following specifications</p>
<ul>
<li>layer 1 uses an LSTM module with 5 hidden units (note here the input_shape = (window_size,1))</li>
<li>layer 2 uses a fully connected module with one unit</li>
<li>the 'mean_squared_error' loss should be used (remember: we are performing regression here)</li>
</ul>
<p>This can be constructed using just a few lines - see e.g., the <a href="https://keras.io/getting-started/sequential-model-guide/">general Keras documentation</a> and the <a href="https://keras.io/layers/recurrent/">LSTM documentation in particular</a> for examples of how to quickly use Keras to build neural network models.  Make sure you are initializing your optimizer given the <a href="https://keras.io/optimizers/">keras-recommended approach for RNNs</a></p>
<p>(given in the cell below).  (remember to copy your completed function into the script <em>my_answers.py</em> function titled <em>build_part1_RNN</em> before submitting your project)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: create required RNN model</span>
<span class="c1"># import keras network libraries - # imported in previous class declaration</span>

<span class="c1"># given - fix random seed - so we can all reproduce the same results on our default time series</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># TODO: implement build_part1_RNN in my_answers.py</span>
<span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="n">build_part1_RNN</span>
<span class="n">model</span>  <span class="o">=</span> <span class="n">build_part1_RNN</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">windowsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="c1"># build model using keras documentation recommended optimizer initialization</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">rmsprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># compile the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mse&#39;</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_9 (LSTM)                (None, 5)                 140       
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 6         
=================================================================
Total params: 146
Trainable params: 146
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With your model built you can now fit the model by activating the cell below!  Note: the number of epochs (np_epochs) and batch_size are preset (so we can all produce the same results).  You can choose to toggle the verbose parameter - which gives you regular updates on the progress of the algorithm - on and off by setting it to 1 or 0 respectively.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># run your model!</span>
<span class="n">checkpointfile_rnn1</span> <span class="o">=</span> <span class="s1">&#39;rnn_part1_lstmm_weights-best.hdf5&#39;</span>
<span class="n">callbacks_rnn</span> <span class="o">=</span> <span class="n">Part1_RNN</span><span class="p">()</span><span class="o">.</span><span class="n">getcallbacks</span><span class="p">(</span><span class="n">checkpointstr</span><span class="o">=</span><span class="n">checkpointfile_rnn1</span><span class="p">,</span>
                                         <span class="n">eval_cb</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># model.load_weights(&#39;checkpoints/rnn_part1_lstmm_weights-best.hdf5&#39;)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">88</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
          <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks_rnn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Epoch 00001: loss improved from inf to 0.14398, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00002: loss did not improve from 0.14398

Epoch 00003: loss improved from 0.14398 to 0.05305, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00004: loss improved from 0.05305 to 0.04910, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00005: loss improved from 0.04910 to 0.04619, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00006: loss improved from 0.04619 to 0.04392, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00007: loss improved from 0.04392 to 0.04210, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00008: loss improved from 0.04210 to 0.04061, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00009: loss improved from 0.04061 to 0.03936, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00010: loss improved from 0.03936 to 0.03829, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00011: loss improved from 0.03829 to 0.03737, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00012: loss improved from 0.03737 to 0.03655, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00013: loss improved from 0.03655 to 0.03583, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00014: loss improved from 0.03583 to 0.03518, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00015: loss improved from 0.03518 to 0.03459, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00016: loss improved from 0.03459 to 0.03405, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00017: loss improved from 0.03405 to 0.03355, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00018: loss improved from 0.03355 to 0.03308, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00019: loss improved from 0.03308 to 0.03265, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00020: loss improved from 0.03265 to 0.03223, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00021: loss improved from 0.03223 to 0.03184, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00022: loss improved from 0.03184 to 0.03146, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00023: loss improved from 0.03146 to 0.03110, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00024: loss improved from 0.03110 to 0.03076, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00025: loss improved from 0.03076 to 0.03042, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00026: loss improved from 0.03042 to 0.03009, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00027: loss improved from 0.03009 to 0.02977, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00028: loss improved from 0.02977 to 0.02945, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00029: loss improved from 0.02945 to 0.02914, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00030: loss improved from 0.02914 to 0.02884, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00031: loss improved from 0.02884 to 0.02854, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00032: loss improved from 0.02854 to 0.02824, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00033: loss improved from 0.02824 to 0.02795, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00034: loss improved from 0.02795 to 0.02766, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00035: loss improved from 0.02766 to 0.02737, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00036: loss improved from 0.02737 to 0.02709, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00037: loss improved from 0.02709 to 0.02681, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00038: loss improved from 0.02681 to 0.02653, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00039: loss improved from 0.02653 to 0.02626, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00040: loss improved from 0.02626 to 0.02599, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00041: loss improved from 0.02599 to 0.02572, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00042: loss improved from 0.02572 to 0.02546, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00043: loss improved from 0.02546 to 0.02520, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00044: loss improved from 0.02520 to 0.02494, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00045: loss improved from 0.02494 to 0.02469, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00046: loss improved from 0.02469 to 0.02445, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00047: loss improved from 0.02445 to 0.02421, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00048: loss improved from 0.02421 to 0.02398, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00049: loss improved from 0.02398 to 0.02375, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00050: loss improved from 0.02375 to 0.02353, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00051: loss improved from 0.02353 to 0.02332, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00052: loss improved from 0.02332 to 0.02311, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00053: loss improved from 0.02311 to 0.02291, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00054: loss improved from 0.02291 to 0.02272, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00055: loss improved from 0.02272 to 0.02253, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00056: loss improved from 0.02253 to 0.02235, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00057: loss improved from 0.02235 to 0.02218, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00058: loss improved from 0.02218 to 0.02201, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00059: loss improved from 0.02201 to 0.02186, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00060: loss improved from 0.02186 to 0.02170, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00061: loss improved from 0.02170 to 0.02156, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00062: loss improved from 0.02156 to 0.02141, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00063: loss improved from 0.02141 to 0.02128, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00064: loss improved from 0.02128 to 0.02115, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00065: loss improved from 0.02115 to 0.02102, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00066: loss improved from 0.02102 to 0.02092, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00067: loss did not improve from 0.02092

Epoch 00068: loss did not improve from 0.02092

Epoch 00069: loss did not improve from 0.02092

Epoch 00070: loss did not improve from 0.02092

Epoch 00071: loss did not improve from 0.02092

Epoch 00072: loss improved from 0.02092 to 0.02087, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00073: loss improved from 0.02087 to 0.02053, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00074: loss improved from 0.02053 to 0.02032, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00075: loss improved from 0.02032 to 0.02018, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00076: loss improved from 0.02018 to 0.02007, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00077: loss improved from 0.02007 to 0.01998, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00078: loss improved from 0.01998 to 0.01990, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00079: loss improved from 0.01990 to 0.01984, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00080: loss improved from 0.01984 to 0.01978, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00081: loss improved from 0.01978 to 0.01975, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00082: loss did not improve from 0.01975

Epoch 00083: loss did not improve from 0.01975

Epoch 00084: loss did not improve from 0.01975

Epoch 00085: loss did not improve from 0.01975

Epoch 00086: loss did not improve from 0.01975

Epoch 00087: loss did not improve from 0.01975

Epoch 00088: loss did not improve from 0.01975

Epoch 00089: loss improved from 0.01975 to 0.01963, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00090: loss improved from 0.01963 to 0.01938, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00091: loss improved from 0.01938 to 0.01925, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00092: loss improved from 0.01925 to 0.01912, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00093: loss improved from 0.01912 to 0.01904, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00094: loss improved from 0.01904 to 0.01897, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00095: loss improved from 0.01897 to 0.01893, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00096: loss improved from 0.01893 to 0.01889, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00097: loss improved from 0.01889 to 0.01888, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00098: loss improved from 0.01888 to 0.01888, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00099: loss did not improve from 0.01888

Epoch 00100: loss did not improve from 0.01888

Epoch 00101: loss did not improve from 0.01888

Epoch 00102: loss did not improve from 0.01888

Epoch 00103: loss improved from 0.01888 to 0.01883, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00104: loss improved from 0.01883 to 0.01870, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00105: loss improved from 0.01870 to 0.01860, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00106: loss improved from 0.01860 to 0.01849, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00107: loss improved from 0.01849 to 0.01842, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00108: loss improved from 0.01842 to 0.01836, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00109: loss improved from 0.01836 to 0.01834, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00110: loss did not improve from 0.01834

Epoch 00111: loss did not improve from 0.01834

Epoch 00112: loss did not improve from 0.01834

Epoch 00113: loss did not improve from 0.01834

Epoch 00114: loss improved from 0.01834 to 0.01824, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00115: loss improved from 0.01824 to 0.01812, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00116: loss improved from 0.01812 to 0.01803, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00117: loss improved from 0.01803 to 0.01796, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00118: loss improved from 0.01796 to 0.01792, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00119: loss improved from 0.01792 to 0.01790, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00120: loss did not improve from 0.01790

Epoch 00121: loss did not improve from 0.01790

Epoch 00122: loss did not improve from 0.01790

Epoch 00123: loss did not improve from 0.01790

Epoch 00124: loss did not improve from 0.01790

Epoch 00125: loss did not improve from 0.01790

Epoch 00126: loss did not improve from 0.01790

Epoch 00127: loss improved from 0.01790 to 0.01778, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00128: loss improved from 0.01778 to 0.01767, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00129: loss improved from 0.01767 to 0.01761, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00130: loss improved from 0.01761 to 0.01757, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00131: loss improved from 0.01757 to 0.01757, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00132: loss did not improve from 0.01757

Epoch 00133: loss did not improve from 0.01757

Epoch 00134: loss did not improve from 0.01757

Epoch 00135: loss did not improve from 0.01757

Epoch 00136: loss did not improve from 0.01757

Epoch 00137: loss did not improve from 0.01757

Epoch 00138: loss improved from 0.01757 to 0.01751, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00139: loss improved from 0.01751 to 0.01748, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00140: loss improved from 0.01748 to 0.01747, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00141: loss did not improve from 0.01747

Epoch 00142: loss did not improve from 0.01747

Epoch 00143: loss did not improve from 0.01747

Epoch 00144: loss improved from 0.01747 to 0.01746, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00145: loss improved from 0.01746 to 0.01744, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00146: loss improved from 0.01744 to 0.01740, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00147: loss improved from 0.01740 to 0.01738, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00148: loss improved from 0.01738 to 0.01737, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00149: loss did not improve from 0.01737

Epoch 00150: loss did not improve from 0.01737

Epoch 00151: loss did not improve from 0.01737

Epoch 00152: loss improved from 0.01737 to 0.01735, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00153: loss improved from 0.01735 to 0.01729, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00154: loss improved from 0.01729 to 0.01722, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00155: loss improved from 0.01722 to 0.01718, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00156: loss improved from 0.01718 to 0.01714, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00157: loss improved from 0.01714 to 0.01713, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00158: loss improved from 0.01713 to 0.01713, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00159: loss did not improve from 0.01713

Epoch 00160: loss did not improve from 0.01713

Epoch 00161: loss did not improve from 0.01713

Epoch 00162: loss did not improve from 0.01713

Epoch 00163: loss did not improve from 0.01713

Epoch 00164: loss improved from 0.01713 to 0.01713, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00165: loss improved from 0.01713 to 0.01709, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00166: loss improved from 0.01709 to 0.01706, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00167: loss improved from 0.01706 to 0.01704, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00168: loss improved from 0.01704 to 0.01704, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00169: loss did not improve from 0.01704

Epoch 00170: loss improved from 0.01704 to 0.01702, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00171: loss improved from 0.01702 to 0.01698, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00172: loss improved from 0.01698 to 0.01694, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00173: loss improved from 0.01694 to 0.01691, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00174: loss improved from 0.01691 to 0.01690, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00175: loss did not improve from 0.01690

Epoch 00176: loss did not improve from 0.01690

Epoch 00177: loss did not improve from 0.01690

Epoch 00178: loss did not improve from 0.01690

Epoch 00179: loss did not improve from 0.01690

Epoch 00180: loss did not improve from 0.01690

Epoch 00181: loss improved from 0.01690 to 0.01688, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00182: loss improved from 0.01688 to 0.01684, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00183: loss improved from 0.01684 to 0.01682, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00184: loss improved from 0.01682 to 0.01681, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00185: loss improved from 0.01681 to 0.01681, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00186: loss improved from 0.01681 to 0.01680, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00187: loss improved from 0.01680 to 0.01679, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00188: loss improved from 0.01679 to 0.01676, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00189: loss improved from 0.01676 to 0.01675, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00190: loss improved from 0.01675 to 0.01673, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00191: loss improved from 0.01673 to 0.01673, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00192: loss improved from 0.01673 to 0.01673, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00193: loss did not improve from 0.01673

Epoch 00194: loss did not improve from 0.01673

Epoch 00195: loss did not improve from 0.01673

Epoch 00196: loss improved from 0.01673 to 0.01671, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00197: loss improved from 0.01671 to 0.01669, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00198: loss improved from 0.01669 to 0.01666, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00199: loss improved from 0.01666 to 0.01665, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00200: loss improved from 0.01665 to 0.01663, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00201: loss improved from 0.01663 to 0.01663, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00202: loss improved from 0.01663 to 0.01662, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00203: loss improved from 0.01662 to 0.01661, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00204: loss improved from 0.01661 to 0.01660, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00205: loss improved from 0.01660 to 0.01659, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00206: loss improved from 0.01659 to 0.01657, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00207: loss improved from 0.01657 to 0.01657, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00208: loss improved from 0.01657 to 0.01656, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00209: loss did not improve from 0.01656

Epoch 00210: loss improved from 0.01656 to 0.01656, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00211: loss improved from 0.01656 to 0.01655, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00212: loss improved from 0.01655 to 0.01653, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00213: loss improved from 0.01653 to 0.01652, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00214: loss improved from 0.01652 to 0.01650, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00215: loss improved from 0.01650 to 0.01650, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00216: loss improved from 0.01650 to 0.01648, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00217: loss improved from 0.01648 to 0.01648, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00218: loss improved from 0.01648 to 0.01647, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00219: loss improved from 0.01647 to 0.01646, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00220: loss improved from 0.01646 to 0.01645, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00221: loss improved from 0.01645 to 0.01644, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00222: loss improved from 0.01644 to 0.01643, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00223: loss improved from 0.01643 to 0.01642, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00224: loss improved from 0.01642 to 0.01642, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00225: loss improved from 0.01642 to 0.01641, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00226: loss improved from 0.01641 to 0.01640, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00227: loss improved from 0.01640 to 0.01640, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00228: loss improved from 0.01640 to 0.01638, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00229: loss improved from 0.01638 to 0.01638, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00230: loss improved from 0.01638 to 0.01636, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00231: loss improved from 0.01636 to 0.01636, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00232: loss improved from 0.01636 to 0.01635, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00233: loss improved from 0.01635 to 0.01634, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00234: loss improved from 0.01634 to 0.01633, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00235: loss improved from 0.01633 to 0.01632, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00236: loss improved from 0.01632 to 0.01631, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00237: loss improved from 0.01631 to 0.01631, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00238: loss improved from 0.01631 to 0.01630, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00239: loss improved from 0.01630 to 0.01630, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00240: loss improved from 0.01630 to 0.01629, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00241: loss improved from 0.01629 to 0.01628, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00242: loss improved from 0.01628 to 0.01627, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00243: loss improved from 0.01627 to 0.01627, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00244: loss improved from 0.01627 to 0.01626, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00245: loss improved from 0.01626 to 0.01625, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00246: loss improved from 0.01625 to 0.01624, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00247: loss improved from 0.01624 to 0.01623, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00248: loss improved from 0.01623 to 0.01622, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00249: loss improved from 0.01622 to 0.01622, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00250: loss improved from 0.01622 to 0.01621, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00251: loss improved from 0.01621 to 0.01620, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00252: loss improved from 0.01620 to 0.01620, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00253: loss improved from 0.01620 to 0.01619, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00254: loss improved from 0.01619 to 0.01618, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00255: loss improved from 0.01618 to 0.01618, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00256: loss improved from 0.01618 to 0.01617, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00257: loss improved from 0.01617 to 0.01617, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00258: loss improved from 0.01617 to 0.01616, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00259: loss improved from 0.01616 to 0.01615, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00260: loss improved from 0.01615 to 0.01614, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00261: loss improved from 0.01614 to 0.01614, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00262: loss improved from 0.01614 to 0.01613, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00263: loss improved from 0.01613 to 0.01612, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00264: loss improved from 0.01612 to 0.01612, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00265: loss improved from 0.01612 to 0.01611, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00266: loss improved from 0.01611 to 0.01610, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00267: loss improved from 0.01610 to 0.01610, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00268: loss improved from 0.01610 to 0.01609, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00269: loss improved from 0.01609 to 0.01609, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00270: loss improved from 0.01609 to 0.01608, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00271: loss improved from 0.01608 to 0.01608, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00272: loss improved from 0.01608 to 0.01607, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00273: loss improved from 0.01607 to 0.01606, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00274: loss improved from 0.01606 to 0.01605, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00275: loss improved from 0.01605 to 0.01605, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00276: loss improved from 0.01605 to 0.01604, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00277: loss improved from 0.01604 to 0.01604, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00278: loss improved from 0.01604 to 0.01603, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00279: loss improved from 0.01603 to 0.01602, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00280: loss improved from 0.01602 to 0.01602, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00281: loss improved from 0.01602 to 0.01601, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00282: loss improved from 0.01601 to 0.01601, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00283: loss improved from 0.01601 to 0.01600, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00284: loss improved from 0.01600 to 0.01600, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00285: loss improved from 0.01600 to 0.01599, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00286: loss improved from 0.01599 to 0.01598, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00287: loss improved from 0.01598 to 0.01598, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00288: loss improved from 0.01598 to 0.01597, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00289: loss improved from 0.01597 to 0.01597, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00290: loss improved from 0.01597 to 0.01596, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00291: loss improved from 0.01596 to 0.01596, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00292: loss improved from 0.01596 to 0.01595, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00293: loss improved from 0.01595 to 0.01595, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00294: loss improved from 0.01595 to 0.01594, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00295: loss improved from 0.01594 to 0.01593, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00296: loss improved from 0.01593 to 0.01593, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00297: loss improved from 0.01593 to 0.01592, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00298: loss improved from 0.01592 to 0.01592, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00299: loss improved from 0.01592 to 0.01591, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00300: loss improved from 0.01591 to 0.01591, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00301: loss improved from 0.01591 to 0.01590, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00302: loss improved from 0.01590 to 0.01590, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00303: loss improved from 0.01590 to 0.01589, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00304: loss improved from 0.01589 to 0.01589, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00305: loss improved from 0.01589 to 0.01588, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00306: loss improved from 0.01588 to 0.01588, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00307: loss improved from 0.01588 to 0.01587, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00308: loss improved from 0.01587 to 0.01587, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00309: loss improved from 0.01587 to 0.01586, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00310: loss improved from 0.01586 to 0.01586, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00311: loss improved from 0.01586 to 0.01585, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00312: loss improved from 0.01585 to 0.01585, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00313: loss improved from 0.01585 to 0.01584, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00314: loss improved from 0.01584 to 0.01584, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00315: loss improved from 0.01584 to 0.01583, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00316: loss improved from 0.01583 to 0.01583, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00317: loss improved from 0.01583 to 0.01582, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00318: loss improved from 0.01582 to 0.01582, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00319: loss improved from 0.01582 to 0.01581, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00320: loss improved from 0.01581 to 0.01581, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00321: loss improved from 0.01581 to 0.01580, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00322: loss improved from 0.01580 to 0.01580, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00323: loss improved from 0.01580 to 0.01579, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00324: loss improved from 0.01579 to 0.01579, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00325: loss improved from 0.01579 to 0.01578, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00326: loss improved from 0.01578 to 0.01578, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00327: loss improved from 0.01578 to 0.01577, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00328: loss improved from 0.01577 to 0.01577, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00329: loss improved from 0.01577 to 0.01577, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00330: loss improved from 0.01577 to 0.01576, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00331: loss improved from 0.01576 to 0.01575, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00332: loss improved from 0.01575 to 0.01575, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00333: loss improved from 0.01575 to 0.01574, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00334: loss improved from 0.01574 to 0.01574, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00335: loss improved from 0.01574 to 0.01574, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00336: loss improved from 0.01574 to 0.01573, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00337: loss improved from 0.01573 to 0.01573, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00338: loss improved from 0.01573 to 0.01572, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00339: loss improved from 0.01572 to 0.01572, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00340: loss improved from 0.01572 to 0.01571, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00341: loss improved from 0.01571 to 0.01571, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00342: loss improved from 0.01571 to 0.01570, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00343: loss improved from 0.01570 to 0.01570, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00344: loss improved from 0.01570 to 0.01570, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00345: loss improved from 0.01570 to 0.01569, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00346: loss improved from 0.01569 to 0.01568, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00347: loss improved from 0.01568 to 0.01568, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00348: loss improved from 0.01568 to 0.01567, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00349: loss improved from 0.01567 to 0.01567, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00350: loss improved from 0.01567 to 0.01567, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00351: loss improved from 0.01567 to 0.01566, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00352: loss improved from 0.01566 to 0.01566, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00353: loss improved from 0.01566 to 0.01565, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00354: loss improved from 0.01565 to 0.01565, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00355: loss improved from 0.01565 to 0.01564, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00356: loss improved from 0.01564 to 0.01564, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00357: loss improved from 0.01564 to 0.01563, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00358: loss improved from 0.01563 to 0.01563, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00359: loss improved from 0.01563 to 0.01563, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00360: loss improved from 0.01563 to 0.01562, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00361: loss improved from 0.01562 to 0.01562, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00362: loss improved from 0.01562 to 0.01561, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00363: loss improved from 0.01561 to 0.01561, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00364: loss improved from 0.01561 to 0.01560, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00365: loss improved from 0.01560 to 0.01560, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00366: loss improved from 0.01560 to 0.01559, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00367: loss improved from 0.01559 to 0.01559, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00368: loss improved from 0.01559 to 0.01559, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00369: loss improved from 0.01559 to 0.01558, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00370: loss improved from 0.01558 to 0.01557, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00371: loss improved from 0.01557 to 0.01557, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00372: loss improved from 0.01557 to 0.01556, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00373: loss improved from 0.01556 to 0.01556, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00374: loss improved from 0.01556 to 0.01556, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00375: loss improved from 0.01556 to 0.01556, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00376: loss improved from 0.01556 to 0.01555, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00377: loss improved from 0.01555 to 0.01555, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00378: loss improved from 0.01555 to 0.01554, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00379: loss improved from 0.01554 to 0.01554, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00380: loss improved from 0.01554 to 0.01553, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00381: loss improved from 0.01553 to 0.01553, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00382: loss improved from 0.01553 to 0.01553, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00383: loss improved from 0.01553 to 0.01552, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00384: loss improved from 0.01552 to 0.01552, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00385: loss improved from 0.01552 to 0.01552, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00386: loss improved from 0.01552 to 0.01551, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00387: loss improved from 0.01551 to 0.01550, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00388: loss improved from 0.01550 to 0.01550, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00389: loss improved from 0.01550 to 0.01550, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00390: loss improved from 0.01550 to 0.01549, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00391: loss improved from 0.01549 to 0.01549, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00392: loss improved from 0.01549 to 0.01549, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00393: loss improved from 0.01549 to 0.01548, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00394: loss improved from 0.01548 to 0.01548, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00395: loss improved from 0.01548 to 0.01547, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00396: loss improved from 0.01547 to 0.01547, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00397: loss improved from 0.01547 to 0.01546, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00398: loss improved from 0.01546 to 0.01546, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00399: loss improved from 0.01546 to 0.01546, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00400: loss improved from 0.01546 to 0.01546, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00401: loss improved from 0.01546 to 0.01545, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00402: loss improved from 0.01545 to 0.01545, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00403: loss improved from 0.01545 to 0.01544, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00404: loss improved from 0.01544 to 0.01543, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00405: loss improved from 0.01543 to 0.01543, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00406: loss improved from 0.01543 to 0.01543, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00407: loss improved from 0.01543 to 0.01543, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00408: loss improved from 0.01543 to 0.01543, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00409: loss improved from 0.01543 to 0.01542, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00410: loss improved from 0.01542 to 0.01542, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00411: loss improved from 0.01542 to 0.01541, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00412: loss improved from 0.01541 to 0.01540, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00413: loss improved from 0.01540 to 0.01540, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00414: loss improved from 0.01540 to 0.01540, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00415: loss improved from 0.01540 to 0.01540, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00416: loss improved from 0.01540 to 0.01540, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00417: loss improved from 0.01540 to 0.01539, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00418: loss improved from 0.01539 to 0.01539, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00419: loss improved from 0.01539 to 0.01538, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00420: loss improved from 0.01538 to 0.01537, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00421: loss improved from 0.01537 to 0.01537, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00422: loss improved from 0.01537 to 0.01537, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00423: loss improved from 0.01537 to 0.01537, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00424: loss improved from 0.01537 to 0.01536, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00425: loss improved from 0.01536 to 0.01536, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00426: loss improved from 0.01536 to 0.01536, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00427: loss improved from 0.01536 to 0.01535, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00428: loss improved from 0.01535 to 0.01534, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00429: loss improved from 0.01534 to 0.01534, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00430: loss improved from 0.01534 to 0.01533, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00431: loss improved from 0.01533 to 0.01533, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00432: loss improved from 0.01533 to 0.01533, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00433: loss did not improve from 0.01533

Epoch 00434: loss improved from 0.01533 to 0.01533, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00435: loss improved from 0.01533 to 0.01533, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00436: loss improved from 0.01533 to 0.01532, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00437: loss improved from 0.01532 to 0.01531, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00438: loss improved from 0.01531 to 0.01531, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00439: loss improved from 0.01531 to 0.01530, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00440: loss improved from 0.01530 to 0.01530, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00441: loss did not improve from 0.01530

Epoch 00442: loss improved from 0.01530 to 0.01530, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00443: loss improved from 0.01530 to 0.01530, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00444: loss improved from 0.01530 to 0.01529, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00445: loss improved from 0.01529 to 0.01528, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00446: loss improved from 0.01528 to 0.01528, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00447: loss improved from 0.01528 to 0.01527, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00448: loss improved from 0.01527 to 0.01527, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00449: loss improved from 0.01527 to 0.01527, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00450: loss improved from 0.01527 to 0.01527, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00451: loss improved from 0.01527 to 0.01527, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00452: loss improved from 0.01527 to 0.01526, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00453: loss improved from 0.01526 to 0.01526, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00454: loss improved from 0.01526 to 0.01525, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00455: loss improved from 0.01525 to 0.01524, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00456: loss improved from 0.01524 to 0.01524, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00457: loss improved from 0.01524 to 0.01524, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00458: loss improved from 0.01524 to 0.01524, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00459: loss did not improve from 0.01524

Epoch 00460: loss improved from 0.01524 to 0.01524, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00461: loss improved from 0.01524 to 0.01523, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00462: loss improved from 0.01523 to 0.01523, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00463: loss improved from 0.01523 to 0.01522, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00464: loss improved from 0.01522 to 0.01521, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00465: loss improved from 0.01521 to 0.01521, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00466: loss improved from 0.01521 to 0.01521, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00467: loss improved from 0.01521 to 0.01521, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00468: loss improved from 0.01521 to 0.01521, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00469: loss improved from 0.01521 to 0.01520, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00470: loss improved from 0.01520 to 0.01520, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00471: loss improved from 0.01520 to 0.01519, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00472: loss improved from 0.01519 to 0.01519, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00473: loss improved from 0.01519 to 0.01518, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00474: loss improved from 0.01518 to 0.01518, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00475: loss improved from 0.01518 to 0.01518, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00476: loss did not improve from 0.01518

Epoch 00477: loss did not improve from 0.01518

Epoch 00478: loss improved from 0.01518 to 0.01517, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00479: loss improved from 0.01517 to 0.01517, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00480: loss improved from 0.01517 to 0.01516, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00481: loss improved from 0.01516 to 0.01514, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00482: loss improved from 0.01514 to 0.01512, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00483: loss improved from 0.01512 to 0.01511, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00484: loss improved from 0.01511 to 0.01510, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00485: loss improved from 0.01510 to 0.01510, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00486: loss improved from 0.01510 to 0.01509, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00487: loss improved from 0.01509 to 0.01507, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00488: loss improved from 0.01507 to 0.01506, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00489: loss improved from 0.01506 to 0.01505, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00490: loss improved from 0.01505 to 0.01504, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00491: loss improved from 0.01504 to 0.01502, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00492: loss improved from 0.01502 to 0.01501, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00493: loss improved from 0.01501 to 0.01501, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00494: loss improved from 0.01501 to 0.01501, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00495: loss improved from 0.01501 to 0.01501, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00496: loss improved from 0.01501 to 0.01500, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00497: loss improved from 0.01500 to 0.01500, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00498: loss improved from 0.01500 to 0.01500, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00499: loss improved from 0.01500 to 0.01499, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00500: loss improved from 0.01499 to 0.01499, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00501: loss improved from 0.01499 to 0.01498, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00502: loss improved from 0.01498 to 0.01498, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00503: loss improved from 0.01498 to 0.01497, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00504: loss did not improve from 0.01497

Epoch 00505: loss improved from 0.01497 to 0.01497, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00506: loss improved from 0.01497 to 0.01496, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00507: loss improved from 0.01496 to 0.01495, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00508: loss improved from 0.01495 to 0.01495, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00509: loss improved from 0.01495 to 0.01495, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00510: loss did not improve from 0.01495

Epoch 00511: loss did not improve from 0.01495

Epoch 00512: loss did not improve from 0.01495

Epoch 00513: loss did not improve from 0.01495

Epoch 00514: loss did not improve from 0.01495

Epoch 00515: loss improved from 0.01495 to 0.01494, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00516: loss improved from 0.01494 to 0.01493, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00517: loss improved from 0.01493 to 0.01493, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00518: loss improved from 0.01493 to 0.01493, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00519: loss improved from 0.01493 to 0.01492, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00520: loss improved from 0.01492 to 0.01492, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00521: loss did not improve from 0.01492

Epoch 00522: loss improved from 0.01492 to 0.01492, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00523: loss improved from 0.01492 to 0.01492, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00524: loss did not improve from 0.01492

Epoch 00525: loss improved from 0.01492 to 0.01491, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00526: loss improved from 0.01491 to 0.01490, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00527: loss improved from 0.01490 to 0.01490, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00528: loss improved from 0.01490 to 0.01490, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00529: loss did not improve from 0.01490

Epoch 00530: loss did not improve from 0.01490

Epoch 00531: loss did not improve from 0.01490

Epoch 00532: loss improved from 0.01490 to 0.01490, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00533: loss improved from 0.01490 to 0.01489, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00534: loss improved from 0.01489 to 0.01488, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00535: loss improved from 0.01488 to 0.01488, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00536: loss improved from 0.01488 to 0.01488, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00537: loss did not improve from 0.01488

Epoch 00538: loss did not improve from 0.01488

Epoch 00539: loss did not improve from 0.01488

Epoch 00540: loss did not improve from 0.01488

Epoch 00541: loss improved from 0.01488 to 0.01487, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00542: loss improved from 0.01487 to 0.01486, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00543: loss improved from 0.01486 to 0.01486, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00544: loss improved from 0.01486 to 0.01485, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00545: loss improved from 0.01485 to 0.01485, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00546: loss did not improve from 0.01485

Epoch 00547: loss did not improve from 0.01485

Epoch 00548: loss improved from 0.01485 to 0.01485, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00549: loss did not improve from 0.01485

Epoch 00550: loss improved from 0.01485 to 0.01485, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00551: loss improved from 0.01485 to 0.01484, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00552: loss improved from 0.01484 to 0.01484, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00553: loss improved from 0.01484 to 0.01484, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00554: loss improved from 0.01484 to 0.01483, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00555: loss did not improve from 0.01483

Epoch 00556: loss improved from 0.01483 to 0.01482, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00557: loss improved from 0.01482 to 0.01482, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00558: loss improved from 0.01482 to 0.01481, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00559: loss did not improve from 0.01481

Epoch 00560: loss improved from 0.01481 to 0.01481, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00561: loss did not improve from 0.01481

Epoch 00562: loss improved from 0.01481 to 0.01481, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00563: loss did not improve from 0.01481

Epoch 00564: loss did not improve from 0.01481

Epoch 00565: loss did not improve from 0.01481

Epoch 00566: loss improved from 0.01481 to 0.01481, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00567: loss improved from 0.01481 to 0.01480, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00568: loss improved from 0.01480 to 0.01479, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00569: loss improved from 0.01479 to 0.01478, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00570: loss improved from 0.01478 to 0.01478, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00571: loss improved from 0.01478 to 0.01478, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00572: loss did not improve from 0.01478

Epoch 00573: loss did not improve from 0.01478

Epoch 00574: loss did not improve from 0.01478

Epoch 00575: loss did not improve from 0.01478

Epoch 00576: loss did not improve from 0.01478

Epoch 00577: loss did not improve from 0.01478

Epoch 00578: loss improved from 0.01478 to 0.01477, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00579: loss improved from 0.01477 to 0.01476, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00580: loss improved from 0.01476 to 0.01476, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00581: loss improved from 0.01476 to 0.01476, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00582: loss improved from 0.01476 to 0.01476, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00583: loss improved from 0.01476 to 0.01476, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00584: loss improved from 0.01476 to 0.01476, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00585: loss improved from 0.01476 to 0.01475, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00586: loss improved from 0.01475 to 0.01475, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00587: loss improved from 0.01475 to 0.01474, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00588: loss improved from 0.01474 to 0.01474, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00589: loss improved from 0.01474 to 0.01474, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00590: loss did not improve from 0.01474

Epoch 00591: loss improved from 0.01474 to 0.01474, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00592: loss improved from 0.01474 to 0.01474, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00593: loss improved from 0.01474 to 0.01473, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00594: loss improved from 0.01473 to 0.01473, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00595: loss improved from 0.01473 to 0.01473, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00596: loss improved from 0.01473 to 0.01472, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00597: loss improved from 0.01472 to 0.01472, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00598: loss improved from 0.01472 to 0.01471, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00599: loss improved from 0.01471 to 0.01471, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00600: loss did not improve from 0.01471

Epoch 00601: loss did not improve from 0.01471

Epoch 00602: loss did not improve from 0.01471

Epoch 00603: loss improved from 0.01471 to 0.01471, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00604: loss improved from 0.01471 to 0.01471, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00605: loss improved from 0.01471 to 0.01470, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00606: loss improved from 0.01470 to 0.01469, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00607: loss improved from 0.01469 to 0.01469, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00608: loss improved from 0.01469 to 0.01469, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00609: loss improved from 0.01469 to 0.01469, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00610: loss did not improve from 0.01469

Epoch 00611: loss improved from 0.01469 to 0.01469, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00612: loss improved from 0.01469 to 0.01468, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00613: loss improved from 0.01468 to 0.01468, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00614: loss improved from 0.01468 to 0.01467, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00615: loss improved from 0.01467 to 0.01467, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00616: loss improved from 0.01467 to 0.01467, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00617: loss improved from 0.01467 to 0.01467, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00618: loss did not improve from 0.01467

Epoch 00619: loss improved from 0.01467 to 0.01467, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00620: loss improved from 0.01467 to 0.01467, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00621: loss improved from 0.01467 to 0.01466, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00622: loss improved from 0.01466 to 0.01466, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00623: loss improved from 0.01466 to 0.01465, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00624: loss improved from 0.01465 to 0.01465, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00625: loss improved from 0.01465 to 0.01465, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00626: loss improved from 0.01465 to 0.01464, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00627: loss did not improve from 0.01464

Epoch 00628: loss did not improve from 0.01464

Epoch 00629: loss improved from 0.01464 to 0.01464, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00630: loss improved from 0.01464 to 0.01463, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00631: loss improved from 0.01463 to 0.01463, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00632: loss improved from 0.01463 to 0.01462, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00633: loss improved from 0.01462 to 0.01462, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00634: loss did not improve from 0.01462

Epoch 00635: loss did not improve from 0.01462

Epoch 00636: loss did not improve from 0.01462

Epoch 00637: loss did not improve from 0.01462

Epoch 00638: loss improved from 0.01462 to 0.01462, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00639: loss improved from 0.01462 to 0.01461, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00640: loss improved from 0.01461 to 0.01461, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00641: loss improved from 0.01461 to 0.01460, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00642: loss improved from 0.01460 to 0.01460, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00643: loss improved from 0.01460 to 0.01460, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00644: loss did not improve from 0.01460

Epoch 00645: loss improved from 0.01460 to 0.01459, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00646: loss improved from 0.01459 to 0.01459, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00647: loss improved from 0.01459 to 0.01458, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00648: loss improved from 0.01458 to 0.01458, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00649: loss improved from 0.01458 to 0.01458, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00650: loss improved from 0.01458 to 0.01458, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00651: loss improved from 0.01458 to 0.01458, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00652: loss improved from 0.01458 to 0.01457, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00653: loss improved from 0.01457 to 0.01457, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00654: loss improved from 0.01457 to 0.01457, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00655: loss improved from 0.01457 to 0.01456, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00656: loss improved from 0.01456 to 0.01456, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00657: loss improved from 0.01456 to 0.01455, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00658: loss improved from 0.01455 to 0.01455, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00659: loss improved from 0.01455 to 0.01454, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00660: loss improved from 0.01454 to 0.01454, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00661: loss improved from 0.01454 to 0.01454, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00662: loss improved from 0.01454 to 0.01453, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00663: loss did not improve from 0.01453

Epoch 00664: loss improved from 0.01453 to 0.01453, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00665: loss improved from 0.01453 to 0.01453, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00666: loss improved from 0.01453 to 0.01452, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00667: loss did not improve from 0.01452

Epoch 00668: loss improved from 0.01452 to 0.01451, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00669: loss improved from 0.01451 to 0.01450, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00670: loss improved from 0.01450 to 0.01450, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00671: loss improved from 0.01450 to 0.01449, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00672: loss did not improve from 0.01449

Epoch 00673: loss did not improve from 0.01449

Epoch 00674: loss did not improve from 0.01449

Epoch 00675: loss did not improve from 0.01449

Epoch 00676: loss did not improve from 0.01449

Epoch 00677: loss improved from 0.01449 to 0.01449, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00678: loss improved from 0.01449 to 0.01448, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00679: loss improved from 0.01448 to 0.01447, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00680: loss improved from 0.01447 to 0.01447, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00681: loss improved from 0.01447 to 0.01446, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00682: loss did not improve from 0.01446

Epoch 00683: loss did not improve from 0.01446

Epoch 00684: loss did not improve from 0.01446

Epoch 00685: loss did not improve from 0.01446

Epoch 00686: loss improved from 0.01446 to 0.01446, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00687: loss improved from 0.01446 to 0.01446, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00688: loss improved from 0.01446 to 0.01445, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00689: loss improved from 0.01445 to 0.01445, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00690: loss improved from 0.01445 to 0.01445, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00691: loss improved from 0.01445 to 0.01444, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00692: loss improved from 0.01444 to 0.01444, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00693: loss improved from 0.01444 to 0.01444, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00694: loss improved from 0.01444 to 0.01443, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00695: loss improved from 0.01443 to 0.01443, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00696: loss improved from 0.01443 to 0.01443, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00697: loss improved from 0.01443 to 0.01442, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00698: loss improved from 0.01442 to 0.01442, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00699: loss improved from 0.01442 to 0.01442, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00700: loss improved from 0.01442 to 0.01441, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00701: loss improved from 0.01441 to 0.01441, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00702: loss improved from 0.01441 to 0.01441, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00703: loss improved from 0.01441 to 0.01440, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00704: loss improved from 0.01440 to 0.01440, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00705: loss improved from 0.01440 to 0.01440, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00706: loss improved from 0.01440 to 0.01439, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00707: loss improved from 0.01439 to 0.01439, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00708: loss improved from 0.01439 to 0.01439, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00709: loss improved from 0.01439 to 0.01439, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00710: loss improved from 0.01439 to 0.01438, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00711: loss improved from 0.01438 to 0.01438, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00712: loss improved from 0.01438 to 0.01437, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00713: loss improved from 0.01437 to 0.01437, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00714: loss improved from 0.01437 to 0.01436, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00715: loss improved from 0.01436 to 0.01436, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00716: loss did not improve from 0.01436

Epoch 00717: loss did not improve from 0.01436

Epoch 00718: loss improved from 0.01436 to 0.01436, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00719: loss improved from 0.01436 to 0.01435, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00720: loss improved from 0.01435 to 0.01435, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00721: loss improved from 0.01435 to 0.01434, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00722: loss improved from 0.01434 to 0.01434, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00723: loss improved from 0.01434 to 0.01433, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00724: loss improved from 0.01433 to 0.01433, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00725: loss improved from 0.01433 to 0.01433, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00726: loss improved from 0.01433 to 0.01433, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00727: loss improved from 0.01433 to 0.01432, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00728: loss improved from 0.01432 to 0.01432, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00729: loss improved from 0.01432 to 0.01432, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00730: loss improved from 0.01432 to 0.01431, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00731: loss improved from 0.01431 to 0.01431, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00732: loss improved from 0.01431 to 0.01431, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00733: loss improved from 0.01431 to 0.01430, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00734: loss improved from 0.01430 to 0.01430, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00735: loss improved from 0.01430 to 0.01429, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00736: loss improved from 0.01429 to 0.01429, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00737: loss improved from 0.01429 to 0.01428, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00738: loss improved from 0.01428 to 0.01428, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00739: loss improved from 0.01428 to 0.01428, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00740: loss improved from 0.01428 to 0.01427, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00741: loss improved from 0.01427 to 0.01427, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00742: loss improved from 0.01427 to 0.01427, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00743: loss improved from 0.01427 to 0.01426, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00744: loss improved from 0.01426 to 0.01426, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00745: loss improved from 0.01426 to 0.01426, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00746: loss improved from 0.01426 to 0.01425, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00747: loss improved from 0.01425 to 0.01425, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00748: loss improved from 0.01425 to 0.01425, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00749: loss improved from 0.01425 to 0.01424, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00750: loss improved from 0.01424 to 0.01424, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00751: loss improved from 0.01424 to 0.01423, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00752: loss did not improve from 0.01423

Epoch 00753: loss improved from 0.01423 to 0.01423, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00754: loss improved from 0.01423 to 0.01422, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00755: loss improved from 0.01422 to 0.01422, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00756: loss improved from 0.01422 to 0.01422, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00757: loss improved from 0.01422 to 0.01421, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00758: loss improved from 0.01421 to 0.01421, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00759: loss improved from 0.01421 to 0.01421, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00760: loss improved from 0.01421 to 0.01420, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00761: loss improved from 0.01420 to 0.01420, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00762: loss improved from 0.01420 to 0.01420, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00763: loss improved from 0.01420 to 0.01419, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00764: loss improved from 0.01419 to 0.01419, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00765: loss improved from 0.01419 to 0.01419, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00766: loss improved from 0.01419 to 0.01418, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00767: loss improved from 0.01418 to 0.01417, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00768: loss improved from 0.01417 to 0.01417, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00769: loss improved from 0.01417 to 0.01417, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00770: loss did not improve from 0.01417

Epoch 00771: loss did not improve from 0.01417

Epoch 00772: loss did not improve from 0.01417

Epoch 00773: loss improved from 0.01417 to 0.01417, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00774: loss improved from 0.01417 to 0.01416, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00775: loss improved from 0.01416 to 0.01415, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00776: loss improved from 0.01415 to 0.01415, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00777: loss improved from 0.01415 to 0.01414, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00778: loss improved from 0.01414 to 0.01414, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00779: loss improved from 0.01414 to 0.01413, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00780: loss improved from 0.01413 to 0.01413, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00781: loss improved from 0.01413 to 0.01413, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00782: loss improved from 0.01413 to 0.01413, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00783: loss improved from 0.01413 to 0.01412, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00784: loss improved from 0.01412 to 0.01412, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00785: loss improved from 0.01412 to 0.01411, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00786: loss did not improve from 0.01411

Epoch 00787: loss improved from 0.01411 to 0.01411, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00788: loss did not improve from 0.01411

Epoch 00789: loss improved from 0.01411 to 0.01411, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00790: loss improved from 0.01411 to 0.01410, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00791: loss improved from 0.01410 to 0.01410, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00792: loss improved from 0.01410 to 0.01409, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00793: loss improved from 0.01409 to 0.01409, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00794: loss improved from 0.01409 to 0.01408, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00795: loss improved from 0.01408 to 0.01408, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00796: loss improved from 0.01408 to 0.01408, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00797: loss improved from 0.01408 to 0.01408, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00798: loss improved from 0.01408 to 0.01407, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00799: loss improved from 0.01407 to 0.01407, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00800: loss improved from 0.01407 to 0.01407, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00801: loss improved from 0.01407 to 0.01406, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00802: loss improved from 0.01406 to 0.01406, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00803: loss improved from 0.01406 to 0.01406, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00804: loss did not improve from 0.01406

Epoch 00805: loss improved from 0.01406 to 0.01405, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00806: loss did not improve from 0.01405

Epoch 00807: loss improved from 0.01405 to 0.01405, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00808: loss improved from 0.01405 to 0.01404, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00809: loss improved from 0.01404 to 0.01404, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00810: loss improved from 0.01404 to 0.01404, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00811: loss improved from 0.01404 to 0.01403, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00812: loss improved from 0.01403 to 0.01403, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00813: loss improved from 0.01403 to 0.01403, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00814: loss did not improve from 0.01403

Epoch 00815: loss improved from 0.01403 to 0.01402, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00816: loss improved from 0.01402 to 0.01402, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00817: loss improved from 0.01402 to 0.01402, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00818: loss improved from 0.01402 to 0.01401, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00819: loss improved from 0.01401 to 0.01401, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00820: loss improved from 0.01401 to 0.01400, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00821: loss improved from 0.01400 to 0.01400, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00822: loss improved from 0.01400 to 0.01400, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00823: loss improved from 0.01400 to 0.01399, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00824: loss improved from 0.01399 to 0.01399, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00825: loss improved from 0.01399 to 0.01399, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00826: loss improved from 0.01399 to 0.01399, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00827: loss improved from 0.01399 to 0.01398, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00828: loss improved from 0.01398 to 0.01398, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00829: loss improved from 0.01398 to 0.01397, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00830: loss improved from 0.01397 to 0.01397, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00831: loss improved from 0.01397 to 0.01397, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00832: loss improved from 0.01397 to 0.01397, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00833: loss improved from 0.01397 to 0.01396, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00834: loss improved from 0.01396 to 0.01396, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00835: loss improved from 0.01396 to 0.01395, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00836: loss improved from 0.01395 to 0.01395, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00837: loss improved from 0.01395 to 0.01395, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00838: loss improved from 0.01395 to 0.01394, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00839: loss improved from 0.01394 to 0.01394, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00840: loss improved from 0.01394 to 0.01394, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00841: loss improved from 0.01394 to 0.01393, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00842: loss improved from 0.01393 to 0.01393, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00843: loss improved from 0.01393 to 0.01392, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00844: loss improved from 0.01392 to 0.01392, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00845: loss improved from 0.01392 to 0.01392, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00846: loss improved from 0.01392 to 0.01392, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00847: loss improved from 0.01392 to 0.01391, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00848: loss improved from 0.01391 to 0.01391, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00849: loss improved from 0.01391 to 0.01391, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00850: loss improved from 0.01391 to 0.01390, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00851: loss improved from 0.01390 to 0.01389, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00852: loss improved from 0.01389 to 0.01389, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00853: loss improved from 0.01389 to 0.01388, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00854: loss improved from 0.01388 to 0.01388, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00855: loss improved from 0.01388 to 0.01388, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00856: loss improved from 0.01388 to 0.01388, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00857: loss improved from 0.01388 to 0.01388, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00858: loss improved from 0.01388 to 0.01387, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00859: loss improved from 0.01387 to 0.01387, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00860: loss improved from 0.01387 to 0.01387, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00861: loss improved from 0.01387 to 0.01386, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00862: loss improved from 0.01386 to 0.01386, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00863: loss improved from 0.01386 to 0.01386, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00864: loss improved from 0.01386 to 0.01385, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00865: loss improved from 0.01385 to 0.01385, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00866: loss improved from 0.01385 to 0.01384, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00867: loss improved from 0.01384 to 0.01384, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00868: loss improved from 0.01384 to 0.01384, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00869: loss improved from 0.01384 to 0.01383, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00870: loss improved from 0.01383 to 0.01383, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00871: loss improved from 0.01383 to 0.01383, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00872: loss improved from 0.01383 to 0.01383, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00873: loss improved from 0.01383 to 0.01382, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00874: loss improved from 0.01382 to 0.01382, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00875: loss improved from 0.01382 to 0.01381, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00876: loss improved from 0.01381 to 0.01381, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00877: loss improved from 0.01381 to 0.01381, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00878: loss improved from 0.01381 to 0.01381, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00879: loss improved from 0.01381 to 0.01380, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00880: loss improved from 0.01380 to 0.01380, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00881: loss improved from 0.01380 to 0.01380, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00882: loss improved from 0.01380 to 0.01379, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00883: loss improved from 0.01379 to 0.01379, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00884: loss improved from 0.01379 to 0.01379, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00885: loss improved from 0.01379 to 0.01379, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00886: loss improved from 0.01379 to 0.01378, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00887: loss improved from 0.01378 to 0.01378, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00888: loss improved from 0.01378 to 0.01378, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00889: loss improved from 0.01378 to 0.01377, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00890: loss improved from 0.01377 to 0.01377, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00891: loss improved from 0.01377 to 0.01377, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00892: loss improved from 0.01377 to 0.01376, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00893: loss improved from 0.01376 to 0.01376, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00894: loss improved from 0.01376 to 0.01376, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00895: loss improved from 0.01376 to 0.01376, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00896: loss improved from 0.01376 to 0.01375, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00897: loss improved from 0.01375 to 0.01375, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00898: loss improved from 0.01375 to 0.01375, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00899: loss improved from 0.01375 to 0.01374, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00900: loss improved from 0.01374 to 0.01374, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00901: loss improved from 0.01374 to 0.01374, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00902: loss improved from 0.01374 to 0.01374, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00903: loss improved from 0.01374 to 0.01373, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00904: loss improved from 0.01373 to 0.01373, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00905: loss improved from 0.01373 to 0.01373, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00906: loss improved from 0.01373 to 0.01373, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00907: loss improved from 0.01373 to 0.01373, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00908: loss improved from 0.01373 to 0.01372, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00909: loss improved from 0.01372 to 0.01372, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00910: loss improved from 0.01372 to 0.01372, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00911: loss improved from 0.01372 to 0.01371, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00912: loss improved from 0.01371 to 0.01371, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00913: loss improved from 0.01371 to 0.01371, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00914: loss improved from 0.01371 to 0.01371, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00915: loss improved from 0.01371 to 0.01371, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00916: loss improved from 0.01371 to 0.01370, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00917: loss improved from 0.01370 to 0.01370, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00918: loss improved from 0.01370 to 0.01370, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00919: loss improved from 0.01370 to 0.01370, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00920: loss improved from 0.01370 to 0.01369, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00921: loss improved from 0.01369 to 0.01369, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00922: loss improved from 0.01369 to 0.01369, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00923: loss improved from 0.01369 to 0.01369, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00924: loss improved from 0.01369 to 0.01368, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00925: loss improved from 0.01368 to 0.01368, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00926: loss improved from 0.01368 to 0.01368, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00927: loss improved from 0.01368 to 0.01368, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00928: loss improved from 0.01368 to 0.01367, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00929: loss improved from 0.01367 to 0.01367, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00930: loss improved from 0.01367 to 0.01367, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00931: loss improved from 0.01367 to 0.01367, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00932: loss improved from 0.01367 to 0.01367, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00933: loss improved from 0.01367 to 0.01366, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00934: loss improved from 0.01366 to 0.01366, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00935: loss improved from 0.01366 to 0.01366, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00936: loss improved from 0.01366 to 0.01366, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00937: loss improved from 0.01366 to 0.01365, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00938: loss improved from 0.01365 to 0.01365, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00939: loss improved from 0.01365 to 0.01365, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00940: loss improved from 0.01365 to 0.01365, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00941: loss improved from 0.01365 to 0.01365, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00942: loss improved from 0.01365 to 0.01364, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00943: loss improved from 0.01364 to 0.01364, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00944: loss improved from 0.01364 to 0.01364, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00945: loss improved from 0.01364 to 0.01364, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00946: loss improved from 0.01364 to 0.01363, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00947: loss improved from 0.01363 to 0.01363, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00948: loss improved from 0.01363 to 0.01363, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00949: loss improved from 0.01363 to 0.01363, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00950: loss improved from 0.01363 to 0.01363, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00951: loss improved from 0.01363 to 0.01362, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00952: loss improved from 0.01362 to 0.01362, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00953: loss improved from 0.01362 to 0.01362, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00954: loss improved from 0.01362 to 0.01362, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00955: loss improved from 0.01362 to 0.01361, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00956: loss improved from 0.01361 to 0.01361, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00957: loss improved from 0.01361 to 0.01361, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00958: loss improved from 0.01361 to 0.01361, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00959: loss improved from 0.01361 to 0.01360, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00960: loss improved from 0.01360 to 0.01360, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00961: loss improved from 0.01360 to 0.01360, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00962: loss improved from 0.01360 to 0.01360, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00963: loss improved from 0.01360 to 0.01360, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00964: loss improved from 0.01360 to 0.01359, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00965: loss improved from 0.01359 to 0.01359, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00966: loss improved from 0.01359 to 0.01359, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00967: loss improved from 0.01359 to 0.01359, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00968: loss improved from 0.01359 to 0.01359, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00969: loss improved from 0.01359 to 0.01358, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00970: loss improved from 0.01358 to 0.01358, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00971: loss improved from 0.01358 to 0.01358, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00972: loss improved from 0.01358 to 0.01358, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00973: loss improved from 0.01358 to 0.01357, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00974: loss improved from 0.01357 to 0.01357, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00975: loss improved from 0.01357 to 0.01357, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00976: loss improved from 0.01357 to 0.01357, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00977: loss improved from 0.01357 to 0.01357, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00978: loss did not improve from 0.01357

Epoch 00979: loss improved from 0.01357 to 0.01356, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00980: loss improved from 0.01356 to 0.01356, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00981: loss improved from 0.01356 to 0.01356, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00982: loss improved from 0.01356 to 0.01356, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00983: loss improved from 0.01356 to 0.01355, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00984: loss improved from 0.01355 to 0.01355, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00985: loss improved from 0.01355 to 0.01355, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00986: loss improved from 0.01355 to 0.01355, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00987: loss improved from 0.01355 to 0.01355, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00988: loss improved from 0.01355 to 0.01355, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00989: loss improved from 0.01355 to 0.01354, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00990: loss did not improve from 0.01354

Epoch 00991: loss improved from 0.01354 to 0.01354, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00992: loss improved from 0.01354 to 0.01354, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00993: loss improved from 0.01354 to 0.01353, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00994: loss improved from 0.01353 to 0.01353, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00995: loss improved from 0.01353 to 0.01353, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00996: loss improved from 0.01353 to 0.01353, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00997: loss improved from 0.01353 to 0.01353, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00998: loss improved from 0.01353 to 0.01353, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 00999: loss improved from 0.01353 to 0.01352, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5

Epoch 01000: loss improved from 0.01352 to 0.01352, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part1_lstmm_weights-best.hdf5
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[77]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x163bd7c0a58&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.5--Checking-model-performance">1.5  Checking model performance<a class="anchor-link" href="#1.5--Checking-model-performance">&#182;</a></h2><p>With your model fit we can now make predictions on both our training and testing sets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># generate predictions for training</span>
<span class="n">train_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">88</span><span class="p">)</span>

<span class="n">test_model</span> <span class="o">=</span> <span class="n">build_part1_RNN</span><span class="p">(</span><span class="n">windowsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">test_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mse&#39;</span><span class="p">])</span>
<span class="n">test_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;checkpoints/rnn_part1_lstmm_weights-best.hdf5&#39;</span><span class="p">)</span>

<span class="n">test_predict</span> <span class="o">=</span> <span class="n">test_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">43</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the next cell we compute training and testing errors using our trained model - you should be able to achieve at least</p>
<p><em>training_error</em> &lt; 0.02</p>
<p>and</p>
<p><em>testing_error</em> &lt; 0.02</p>
<p>with your fully trained model.</p>
<p>If either or both of your accuracies are larger than 0.02 re-train your model - increasing the number of epochs you take (a maximum of around 1,000 should do the job) and/or adjusting your batch_size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># print out training and testing errors</span>
<span class="n">training_error</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">88</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;training error = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">training_error</span><span class="p">))</span>

<span class="n">testing_error</span> <span class="o">=</span> <span class="n">test_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">43</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;testing error = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">testing_error</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>training error = [0.01352131087332964, 0.01352131087332964]
testing error = [0.020838681608438492, 0.020838681608438492]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Activating the next cell plots the original data, as well as both predictions on the training and testing sets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[80]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Plot everything - the original series as well as predictions on training and testing sets</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># plot original series</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="c1"># plot training set prediction</span>
<span class="n">split_pt</span> <span class="o">=</span> <span class="n">train_test_split</span> <span class="o">+</span> <span class="n">window_size</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">window_size</span><span class="p">,</span><span class="n">split_pt</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">train_predict</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>

<span class="c1"># plot testing set prediction</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">split_pt</span><span class="p">,</span><span class="n">split_pt</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_predict</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span><span class="n">test_predict</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="c1"># pretty up graph</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;day&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;(normalized) price of Apple stock&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;original series&#39;</span><span class="p">,</span><span class="s1">&#39;training fit&#39;</span><span class="p">,</span><span class="s1">&#39;testing fit&#39;</span><span class="p">],</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center left&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Note:</strong> you can try out any time series for this exercise!  If you would like to try another see e.g., <a href="https://datamarket.com/data/list/?q=provider%3Atsdl">this site containing thousands of time series</a> and pick another one!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Problem-2:-Create-a-sequence-generator">Problem 2: Create a sequence generator<a class="anchor-link" href="#Problem-2:-Create-a-sequence-generator">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.1--Getting-started">2.1  Getting started<a class="anchor-link" href="#2.1--Getting-started">&#182;</a></h2><p>In this project you will implement a popular Recurrent Neural Network (RNN) architecture to create an English language sequence generator capable of building semi-coherent English sentences from scratch by building them up character-by-character.  This will require a substantial amount amount of parameter tuning on a large training corpus (at least 100,000 characters long).  In particular for this project we will be using a complete version of Sir Arthur Conan Doyle's classic book The Adventures of Sherlock Holmes.</p>
<p>How can we train a machine learning model to generate text automatically, character-by-character?  <em>By showing the model many training examples so it can learn a pattern between input and output.</em>  With this type of text generation each input is a string of valid characters like this one</p>
<p><em>dogs are grea</em></p>
<p>while the corresponding output is the next character in the sentence - which here is 't' (since the complete sentence is 'dogs are great').  We need to show a model many such examples in order for it to make reasonable predictions.</p>
<p><strong>Fun note:</strong> For those interested in how text generation is being used check out some of the following fun resources:</p>
<ul>
<li><p><a href="http://www.cs.toronto.edu/~ilya/rnn.html">Generate wacky sentences</a> with this academic RNN text generator</p>
</li>
<li><p>Various twitter bots that tweet automatically generated text like<a href="http://tweet-generator-alex.herokuapp.com/">this one</a>.</p>
</li>
<li><p>the <a href="https://github.com/NaNoGenMo/2016">NanoGenMo</a> annual contest to automatically produce a 50,000+ novel automatically</p>
</li>
<li><p><a href="https://github.com/genekogan/RobotShakespeare">Robot Shakespeare</a> a text generator that automatically produces Shakespear-esk sentences</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.2--Preprocessing-a-text-dataset">2.2  Preprocessing a text dataset<a class="anchor-link" href="#2.2--Preprocessing-a-text-dataset">&#182;</a></h2><p>Our first task is to get a large text corpus for use in training, and on it we perform a several light pre-processing tasks.  The default corpus we will use is the classic book Sherlock Holmes, but you can use a variety of others as well - so long as they are fairly large (around 100,000 characters or more).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># read in the text, transforming everything to lower case</span>
<span class="n">text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;datasets/holmes.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;our original text has &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; characters&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>our original text has 581881 characters
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, lets examine a bit of the raw text.  Because we are interested in creating sentences of English words automatically by building up each word character-by-character, we only want to train on valid English words.  In other words - we need to remove all of the other characters that are not part of English words.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[82]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### print out the first 1000 characters of the raw text to get a sense of what we need to throw out</span>
<span class="n">text</span><span class="p">[</span><span class="mi">1300</span><span class="p">:</span><span class="mi">2000</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[82]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;in his eyes she eclipses\nand predominates the whole of her sex. it was not that he felt\nany emotion akin to love for irene adler. all emotions, and that\none particularly, were abhorrent to his cold, precise but\nadmirably balanced mind. he was, i take it, the most perfect\nreasoning and observing machine that the world has seen, but as a\nlover he would have placed himself in a false position. he never\nspoke of the softer passions, save with a gibe and a sneer. they\nwere admirable things for the observer--excellent for drawing the\nveil from men&#39;s motives and actions. but for the trained reasoner\nto admit such intrusions into his own delicate and finely\nadjusted temperament was to introduce a di&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Wow - there's a lot of junk here (i.e., weird uncommon character combinations - as this first character chunk contains the title and author page, as well as table of contents)!  To keep things simple, we want to train our RNN on a large chunk of more typical English sentences - we don't want it to start thinking non-english words or strange characters are valid! - so lets clean up the data a bit.</p>
<p>First, since the dataset is so large and the first few hundred characters contain a lot of junk, lets cut it out.  Lets also find-and-replace those newline tags with empty spaces.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets see how the first 1000 characters of our text looks now!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">cleaned_text_nb</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">string</span> <span class="k">import</span> <span class="n">ascii_lowercase</span><span class="p">,</span> <span class="n">whitespace</span><span class="p">,</span> <span class="n">digits</span>
    <span class="n">punctuation</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;;&#39;</span><span class="p">,</span> <span class="s1">&#39;?&#39;</span><span class="p">]</span>
    <span class="n">filter_</span> <span class="o">=</span> <span class="n">ascii_lowercase</span><span class="o">+</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">punctuation</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;`&#39; &quot;</span><span class="o">+</span><span class="s1">&#39;&quot;&#39;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span> <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="ow">in</span> <span class="n">whitespace</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span> <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">filter_</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="n">text</span>  <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### find and replace &#39;\n&#39; and &#39;\r&#39; symbols - replacing them </span>
<span class="c1"># replacing &#39;\n&#39; with &#39;&#39; simply removes the sequence</span>
<span class="c1">### print out the first 1000 characters of the raw text to get a sense of what we need to throw out</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="mi">1300</span><span class="p">:]</span>
<span class="n">cleaned_text_nb</span><span class="p">(</span><span class="n">text</span><span class="p">[:</span><span class="mi">1000</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[84]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;in his eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer excellent for drawing the veil from men&#39;s motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late iren&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='TODO_3'></a></p>
<h4 id="TODO:-finish-cleaning-the-text">TODO: finish cleaning the text<a class="anchor-link" href="#TODO:-finish-cleaning-the-text">&#182;</a></h4><p>Lets make sure we haven't left any other atypical characters (commas, periods, etc., are ok) lurking around in the depths of the text.  You can do this by enumerating all the text's unique characters, examining them, and then replacing any unwanted characters with empty spaces!  Once we find all of the text's unique characters, we can remove all of the atypical ones in the next cell.  Note: don't remove the punctuation marks given in my_answers.py.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: implement cleaned_text in my_answers.py</span>
<span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="n">cleaned_text</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">cleaned_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With your chosen characters removed print out the first few hundred lines again just to double check that everything looks good.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### print out the first 2000 characters of the raw text to get a sense of what we need to throw out</span>
<span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[86]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;in his eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer excellent for drawing the veil from men s motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene adler, of dubious and questionable memory. i had seen little of holmes lately. my marriage had drifted us away from each other. my own complete happiness, and the home centred interests which rise up around the man who first finds himself master of his own establishment, were sufficient to absorb all my attention, while holmes, who loathed every form of society with his whole bohemian soul, remained in our lodgings in baker street, buried among his old books, and alternating from week to week between cocaine and ambition, the drowsiness of the drug, and the fierce energy of his own keen nature. he was still, as ever, deeply attracted by the study of crime, and occupied his immense faculties and extraordinary powers of observation in following out those clues, and clearing up those mysteries which had been abandoned as hopeless by the official police. from time to time i heard some vague account of his doings: of his summons to odessa in the case of the trepoff murder, of his clearing &#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have thrown out a good number of non-English characters/character sequences lets print out some statistics about the dataset - including number of total characters and number of unique characters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># count the number of unique characters in the text</span>
<span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>

<span class="c1"># print some of the text, as well as statistics</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;this corpus has &quot;</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot; total number of characters&quot;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;this corpus has &quot;</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot; unique characters&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>this corpus has 570574 total number of characters
this corpus has 33 unique characters
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.3--Cutting-data-into-input/output-pairs">2.3  Cutting data into input/output pairs<a class="anchor-link" href="#2.3--Cutting-data-into-input/output-pairs">&#182;</a></h2><p>Now that we have our text all cleaned up, how can we use it to train a model to generate sentences automatically?  First we need to train a machine learning model - and in order to do that we need a set of input/output pairs for a model to train on.  How can we create a set of input/output pairs from our text to train on?</p>
<p>Remember in part 1 of this notebook how we used a sliding window to extract input/output pairs from a time series?  We do the same thing here!  We slide a window of length $T$ along our giant text corpus - everything in the window becomes one input while the character following becomes its corresponding output.  This process of extracting input/output pairs is illustrated in the gif below on a small example text using a window size of T = 5.</p>
<p><img src="images/text_windowing_training.gif" width=400 height=400/></p>
<p>Notice one aspect of the sliding window in this gif that does not mirror the analogous gif for time series shown in part 1 of the notebook - we do not need to slide the window along one character at a time but can move by a fixed step size $M$ greater than 1 (in the gif indeed $M = 1$).  This is done with large input texts (like ours which has over 500,000 characters!) when sliding the window along one character at a time we would create far too many input/output pairs to be able to reasonably compute with.</p>
<p>More formally lets denote our text corpus - which is one long string of characters - as follows</p>
<p>$$s_{0},s_{1},s_{2},...,s_{P}$$</p>
<p>where $P$ is the length of the text (again for our text $P \approx 500,000!$).  Sliding a window of size T = 5 with a step length of M = 1 (these are the parameters shown in the gif above) over this sequence produces the following list of input/output pairs</p>
<p>$$\begin{array}{c|c}
\text{Input} &amp; \text{Output}\\
\hline \color{CornflowerBlue} {\langle s_{1},s_{2},s_{3},s_{4},s_{5}\rangle} &amp; \color{Goldenrod}{ s_{6}} \\
\ \color{CornflowerBlue} {\langle s_{2},s_{3},s_{4},s_{5},s_{6} \rangle } &amp; \color{Goldenrod} {s_{7} } \\
\color{CornflowerBlue}  {\vdots} &amp; \color{Goldenrod} {\vdots}\\
\color{CornflowerBlue} { \langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \rangle } &amp; \color{Goldenrod} {s_{P}}
\end{array}$$</p>
<p>Notice here that each input is a sequence (or vector) of 5 characters (and in general has length equal to the window size T) while each corresponding output is a single character.  We created around P total number of input/output pairs  (for general step size M we create around ceil(P/M) pairs).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">window_transform_text_nb</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">wSize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span>  <span class="o">=</span> <span class="p">[],[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">wSize</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">_</span><span class="p">:</span><span class="n">_</span><span class="o">+</span><span class="n">wSize</span><span class="p">])</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">_</span><span class="o">+</span><span class="n">wSize</span><span class="p">])</span>
        
    <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='TODO_4'></a></p>
<p>Now its time for you to window the input time series as described above!</p>
<p><strong>TODO:</strong> Create a function that runs a sliding window along the input text and creates associated input/output pairs.  A skeleton function has been provided for you.  Note that this function should input a) the text  b) the window size and c) the step size, and return the input/output sequences.  Note: the return items should be <em>lists</em> - not numpy arrays.</p>
<p>(remember to copy your completed function into the script <em>my_answers.py</em> function titled <em>window_transform_text</em> before submitting your project)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: implement window_transform_series in my_answers.py</span>
<span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="n">window_transform_text</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With our function complete we can now use it to produce input/output pairs!  We employ the function in the next cell, where the window_size = 50 and step_size = 5.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># run your text window-ing function </span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">window_transform_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">window_size</span><span class="p">,</span><span class="n">step_size</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets print out a few input/output pairs to verify that we have made the right sort of stuff!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># print out a few of the input/output pairs to verify that we&#39;ve made the right kind of stuff to learn from</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;input = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;output = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--------------&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;input = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">100</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;output = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">100</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>input = s she eclipses and predominates the whole of her s
output = e
--------------
input = server excellent for drawing the veil from men s m
output = o
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks good!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.4--Wait,-what-kind-of-problem-is-text-generation-again?">2.4  Wait, what kind of problem is text generation again?<a class="anchor-link" href="#2.4--Wait,-what-kind-of-problem-is-text-generation-again?">&#182;</a></h2><p>In part 1 of this notebook we used the same pre-processing technique - the sliding window - to produce a set of training input/output pairs to tackle the problem of time series prediction <em>by treating the problem as one of regression</em>.  So what sort of problem do we have here now, with text generation?  Well, the time series prediction was a regression problem because the output (one value of the time series) was a continuous value.  Here - for character-by-character text generation - each output is a <em>single character</em>.  This isn't a continuous value - but a distinct class - therefore <strong>character-by-character text generation is a classification problem</strong>.</p>
<p>How many classes are there in the data?  Well, the number of classes is equal to the number of unique characters we have to predict!  How many of those were there in our dataset again?  Lets print out the value again.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># print out the number of unique characters in the dataset</span>
<span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">outputs</span><span class="p">)))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;this corpus has &quot;</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot; unique characters&quot;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;and these characters are &#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">chars</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>this corpus has 33 unique characters
and these characters are 
[&#39; &#39;, &#39;!&#39;, &#39;,&#39;, &#39;.&#39;, &#39;:&#39;, &#39;;&#39;, &#39;?&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;, &#39;k&#39;, &#39;l&#39;, &#39;m&#39;, &#39;n&#39;, &#39;o&#39;, &#39;p&#39;, &#39;q&#39;, &#39;r&#39;, &#39;s&#39;, &#39;t&#39;, &#39;u&#39;, &#39;v&#39;, &#39;w&#39;, &#39;x&#39;, &#39;y&#39;, &#39;z&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Rockin' - so we have a multiclass classification problem on our hands!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.5--One-hot-encoding-characters">2.5  One-hot encoding characters<a class="anchor-link" href="#2.5--One-hot-encoding-characters">&#182;</a></h2><p>The last issue we have to deal with is representing our text data as numerical data so that we can use it as an input to a neural network. One of the conceptually simplest ways of doing this is via a 'one-hot encoding' scheme.  Here's how it works.</p>
<p>We transform each character in our inputs/outputs into a vector with length equal to the number of unique characters in our text.  This vector is all zeros except one location where we place a 1 - and this location is unique to each character type.  e.g., we transform 'a', 'b', and 'c' as follows</p>
<p>$$a\longleftarrow\left[\begin{array}{c}
1\\
0\\
0\\
\vdots\\
0\\
0
\end{array}\right]\,\,\,\,\,\,\,b\longleftarrow\left[\begin{array}{c}
0\\
1\\
0\\
\vdots\\
0\\
0
\end{array}\right]\,\,\,\,\,c\longleftarrow\left[\begin{array}{c}
0\\
0\\
1\\
\vdots\\
0\\
0 
\end{array}\right]\cdots$$</p>
<p>where each vector has 32 entries (or in general: number of entries = number of unique characters in text).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first practical step towards doing this one-hot encoding is to form a dictionary mapping each unique character to a unique integer, and one dictionary to do the reverse mapping.  We can then use these dictionaries to quickly make our one-hot encodings, as well as re-translate (from integers to characters) the results of our trained RNN classification model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[93]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># this dictionary is a function mapping each unique character to a unique integer</span>
<span class="n">chars_to_indices</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>  <span class="c1"># map each unique character to unique integer</span>

<span class="c1"># this dictionary is a function mapping each unique integer back to a unique character</span>
<span class="n">indices_to_chars</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>  <span class="c1"># map each unique integer back to unique character</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can transform our input/output pairs - consisting of characters - to equivalent input/output pairs made up of one-hot encoded vectors.  In the next cell we provide a function for doing just this: it takes in the raw character input/outputs and returns their numerical versions.  In particular the numerical input is given as $\bf{X}$, and numerical output is given as the $\bf{y}$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># transform character-based input/output into equivalent numerical versions</span>
<span class="k">def</span> <span class="nf">encode_io_pairs</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">window_size</span><span class="p">,</span><span class="n">step_size</span><span class="p">):</span>
    <span class="c1"># number of unique chars</span>
    <span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>
    <span class="n">num_chars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>
    
    <span class="c1"># cut up text into character input/output pairs</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">window_transform_text_nb</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">window_size</span><span class="p">,</span><span class="n">step_size</span><span class="p">)</span>
    
    <span class="c1"># create empty vessels for one-hot encoded input/output</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">num_chars</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">num_chars</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    
    <span class="c1"># loop over inputs/outputs and transform and store in X/y</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
            <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">chars_to_indices</span><span class="p">[</span><span class="n">char</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">chars_to_indices</span><span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">]]]</span> <span class="o">=</span> <span class="mi">1</span>
        
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span><span class="n">y</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now run the one-hot encoding function by activating the cell below and transform our input/output pairs!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># use your function</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">encode_io_pairs</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">window_size</span><span class="p">,</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[95]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((114095, 100, 33), (114095, 33))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">itemsize</span> <span class="o">+</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">itemsize</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">+</span><span class="s1">&#39; MiBs.&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>362.66196727752686 MiBs.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='TODO_5'></a></p>
<h2 id="2.6-Setting-up-our-RNN">2.6 Setting up our RNN<a class="anchor-link" href="#2.6-Setting-up-our-RNN">&#182;</a></h2><p>With our dataset loaded and the input/output pairs extracted / transformed we can now begin setting up our RNN for training.  Again we will use Keras to quickly build a single hidden layer RNN - where our hidden layer consists of LSTM modules.</p>
<p>Time to get to work: build a 3 layer RNN model of the following specification</p>
<ul>
<li>layer 1 should be an LSTM module with 200 hidden units --&gt; note this should have input_shape = (window_size,len(chars)) where len(chars) = number of unique characters in your cleaned text</li>
<li>layer 2 should be a linear module, fully connected, with len(chars) hidden units --&gt; where len(chars) = number of unique characters in your cleaned text</li>
<li>layer 3 should be a softmax activation ( since we are solving a <em>multiclass classification</em>)</li>
<li>Use the <strong>categorical_crossentropy</strong> loss </li>
</ul>
<p>This network can be constructed using just a few lines - as with the RNN network you made in part 1 of this notebook.  See e.g., the <a href="https://keras.io/getting-started/sequential-model-guide/">general Keras documentation</a> and the <a href="https://keras.io/layers/recurrent/">LSTM documentation in particular</a> for examples of how to quickly use Keras to build neural network models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="n">Part2_RNN</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">build_part2_RNN</span><span class="p">(</span><span class="n">windowsize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">numchars</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="k">del</span> <span class="n">m</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_12 (LSTM)               (None, 200)               187200    
_________________________________________________________________
dense_17 (Dense)             (None, 33)                6633      
_________________________________________________________________
activation_8 (Activation)    (None, 33)                0         
=================================================================
Total params: 193,833
Trainable params: 193,833
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.7--Training-our-RNN-model-for-text-generation">2.7  Training our RNN model for text generation<a class="anchor-link" href="#2.7--Training-our-RNN-model-for-text-generation">&#182;</a></h2><p>With our RNN setup we can now train it!  Lets begin by trying it out on a small subset of the larger version.  In the next cell we take the first 10,000 input/output pairs from our training database to learn on.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[98]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># a small subset of our input/output pairs</span>
<span class="n">Xsmall</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">1000</span><span class="p">:</span><span class="mi">11000</span><span class="p">,:,:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
<span class="n">ysmall</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">1000</span><span class="p">:</span><span class="mi">11000</span><span class="p">,:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>

<span class="n">xval</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">11000</span><span class="p">:</span><span class="mi">12000</span><span class="p">,:,:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
<span class="n">yval</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">11000</span><span class="p">:</span><span class="mi">12000</span><span class="p">,:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">weightclasses</span><span class="p">(</span><span class="n">xseq</span><span class="p">,</span> <span class="n">yseq</span><span class="p">):</span>
    <span class="n">Sample_tf</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({</span><span class="n">x</span><span class="p">:</span><span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">xseq</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])})</span>
    <span class="n">Sample_idf</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({</span><span class="n">x</span><span class="p">:</span><span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">xseq</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])})</span>
    <span class="n">Sample_tfidf</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({</span><span class="n">x</span><span class="p">:</span><span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">xseq</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])})</span>
    
    <span class="n">seqlength</span> <span class="o">=</span> <span class="n">yseq</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">doclength</span> <span class="o">=</span> <span class="n">xseq</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="p">(</span><span class="n">xseq</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">xseq</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">yseq</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yseq</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xseq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">xseq</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">x_</span><span class="p">,</span><span class="n">y_</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">xseq</span><span class="p">,</span><span class="n">yseq</span><span class="p">):</span>
        <span class="n">Sample_idf</span><span class="p">[</span><span class="n">y_</span><span class="p">]</span> <span class="o">+=</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">keys</span> <span class="ow">in</span> <span class="n">x_</span><span class="p">:</span>
                <span class="n">Sample_tf</span><span class="p">[</span><span class="n">keys</span><span class="p">]</span> <span class="o">+=</span><span class="mi">1</span><span class="o">/</span><span class="n">doclength</span>
    <span class="c1">#print(&#39;\n&#39;)</span>
    <span class="k">for</span> <span class="n">keys</span> <span class="ow">in</span> <span class="n">Sample_tf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">Sample_tf</span><span class="p">[</span><span class="n">keys</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">Sample_tf</span><span class="p">[</span><span class="n">keys</span><span class="p">])</span>
        <span class="n">Sample_idf</span><span class="p">[</span><span class="n">keys</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">seqlength</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">Sample_idf</span><span class="p">[</span><span class="n">keys</span><span class="p">]))</span>
        <span class="n">Sample_tfidf</span><span class="p">[</span><span class="n">keys</span><span class="p">]</span> <span class="o">=</span> <span class="n">Sample_idf</span><span class="p">[</span><span class="n">keys</span><span class="p">]</span> <span class="o">*</span> <span class="n">Sample_tf</span><span class="p">[</span><span class="n">keys</span><span class="p">]</span>
        <span class="c1">#print(keys, Sample_tf[keys], Sample_idf[keys], Sample_tfidf[keys])</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="o">/</span><span class="mf">1.</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">Sample_tfidf</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
    

<span class="n">Global_weights</span> <span class="o">=</span> <span class="n">weightclasses</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">Class_weights</span> <span class="o">=</span> <span class="n">weightclasses</span><span class="p">(</span><span class="n">Xsmall</span><span class="p">,</span><span class="n">ysmall</span><span class="p">)</span>
<span class="n">Class_weights_val</span> <span class="o">=</span> <span class="n">weightclasses</span><span class="p">(</span><span class="n">xval</span><span class="p">,</span> <span class="n">yval</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Class_weights</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span> <span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Small Set&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Class_weights_val</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mini Set&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Global_weights</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;All Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;vocab sequences&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;tfidf scores&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center left&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="n">build_part2_RNN</span>
<span class="c1">### necessary functions from the keras library    </span>
<span class="n">clear_start</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>


<span class="c1"># TODO implement build_part2_RNN in my_answers.py</span>
<span class="n">checkpointfile_rnn2</span> <span class="o">=</span> <span class="s1">&#39;rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">build_part2_RNN</span><span class="p">(</span><span class="n">windowsize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">numchars</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>

<span class="c1"># initialize optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">rmsprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># compile model --&gt; make sure initialized optimizer and callbacks - as defined above - are used</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now lets fit our model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># train the model</span>
<span class="n">callbacks_rnn</span> <span class="o">=</span> <span class="n">Part1_RNN</span><span class="p">()</span><span class="o">.</span><span class="n">getcallbacks</span><span class="p">(</span><span class="n">checkpointstr</span><span class="o">=</span><span class="n">checkpointfile_rnn2</span><span class="p">,</span>
                                         <span class="n">eval_cb</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># model.load_weights(&#39;checkpoints/rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5&#39;)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xsmall</span><span class="p">,</span> <span class="n">ysmall</span><span class="p">,</span> 
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
          <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_rnn</span><span class="p">,</span>
          <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
          <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/100
10000/10000 [==============================] - 3s 288us/step - loss: 3.0356

Epoch 00001: loss improved from inf to 3.03560, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 2/100
10000/10000 [==============================] - 2s 239us/step - loss: 2.8968

Epoch 00002: loss improved from 3.03560 to 2.89684, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 3/100
10000/10000 [==============================] - 2s 238us/step - loss: 2.8710

Epoch 00003: loss improved from 2.89684 to 2.87102, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 4/100
10000/10000 [==============================] - 2s 237us/step - loss: 2.8340

Epoch 00004: loss improved from 2.87102 to 2.83396, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 5/100
10000/10000 [==============================] - 2s 244us/step - loss: 2.7653

Epoch 00005: loss improved from 2.83396 to 2.76535, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 6/100
10000/10000 [==============================] - 2s 239us/step - loss: 2.6921

Epoch 00006: loss improved from 2.76535 to 2.69209, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 7/100
10000/10000 [==============================] - 2s 238us/step - loss: 2.6147

Epoch 00007: loss improved from 2.69209 to 2.61471, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 8/100
10000/10000 [==============================] - 2s 242us/step - loss: 2.5430

Epoch 00008: loss improved from 2.61471 to 2.54298, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 9/100
10000/10000 [==============================] - 2s 235us/step - loss: 2.4824

Epoch 00009: loss improved from 2.54298 to 2.48242, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 10/100
10000/10000 [==============================] - 2s 233us/step - loss: 2.4331

Epoch 00010: loss improved from 2.48242 to 2.43311, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 11/100
10000/10000 [==============================] - 2s 234us/step - loss: 2.3868

Epoch 00011: loss improved from 2.43311 to 2.38681, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 12/100
10000/10000 [==============================] - 2s 234us/step - loss: 2.3489

Epoch 00012: loss improved from 2.38681 to 2.34892, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 13/100
10000/10000 [==============================] - 2s 236us/step - loss: 2.3204

Epoch 00013: loss improved from 2.34892 to 2.32035, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 14/100
10000/10000 [==============================] - 2s 235us/step - loss: 2.2860

Epoch 00014: loss improved from 2.32035 to 2.28597, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 15/100
10000/10000 [==============================] - 2s 232us/step - loss: 2.2619

Epoch 00015: loss improved from 2.28597 to 2.26194, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 16/100
10000/10000 [==============================] - 2s 234us/step - loss: 2.2361

Epoch 00016: loss improved from 2.26194 to 2.23606, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 17/100
10000/10000 [==============================] - 2s 233us/step - loss: 2.2119

Epoch 00017: loss improved from 2.23606 to 2.21190, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 18/100
10000/10000 [==============================] - 2s 232us/step - loss: 2.1933

Epoch 00018: loss improved from 2.21190 to 2.19328, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 19/100
10000/10000 [==============================] - 2s 233us/step - loss: 2.1694

Epoch 00019: loss improved from 2.19328 to 2.16937, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 20/100
10000/10000 [==============================] - 2s 233us/step - loss: 2.1475

Epoch 00020: loss improved from 2.16937 to 2.14753, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 21/100
10000/10000 [==============================] - 2s 236us/step - loss: 2.1287

Epoch 00021: loss improved from 2.14753 to 2.12870, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 22/100
10000/10000 [==============================] - 2s 239us/step - loss: 2.1094

Epoch 00022: loss improved from 2.12870 to 2.10940, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 23/100
10000/10000 [==============================] - 2s 237us/step - loss: 2.0871

Epoch 00023: loss improved from 2.10940 to 2.08710, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 24/100
10000/10000 [==============================] - 2s 238us/step - loss: 2.0697

Epoch 00024: loss improved from 2.08710 to 2.06975, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 25/100
10000/10000 [==============================] - 2s 234us/step - loss: 2.0476

Epoch 00025: loss improved from 2.06975 to 2.04760, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 26/100
10000/10000 [==============================] - 2s 234us/step - loss: 2.0290

Epoch 00026: loss improved from 2.04760 to 2.02898, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 27/100
10000/10000 [==============================] - 2s 240us/step - loss: 2.0046

Epoch 00027: loss improved from 2.02898 to 2.00458, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 28/100
10000/10000 [==============================] - 2s 244us/step - loss: 1.9871

Epoch 00028: loss improved from 2.00458 to 1.98714, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 29/100
10000/10000 [==============================] - 2s 248us/step - loss: 1.9700

Epoch 00029: loss improved from 1.98714 to 1.96997, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 30/100
10000/10000 [==============================] - 2s 244us/step - loss: 1.9437

Epoch 00030: loss improved from 1.96997 to 1.94370, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 31/100
10000/10000 [==============================] - 2s 240us/step - loss: 1.9256

Epoch 00031: loss improved from 1.94370 to 1.92561, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 32/100
10000/10000 [==============================] - 2s 234us/step - loss: 1.9030

Epoch 00032: loss improved from 1.92561 to 1.90304, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 33/100
10000/10000 [==============================] - 2s 235us/step - loss: 1.8826

Epoch 00033: loss improved from 1.90304 to 1.88257, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 34/100
10000/10000 [==============================] - 2s 234us/step - loss: 1.8630

Epoch 00034: loss improved from 1.88257 to 1.86296, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 35/100
10000/10000 [==============================] - 2s 235us/step - loss: 1.8357

Epoch 00035: loss improved from 1.86296 to 1.83572, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 36/100
10000/10000 [==============================] - 2s 234us/step - loss: 1.8211

Epoch 00036: loss improved from 1.83572 to 1.82105, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 37/100
10000/10000 [==============================] - 2s 232us/step - loss: 1.7917

Epoch 00037: loss improved from 1.82105 to 1.79165, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 38/100
10000/10000 [==============================] - 2s 234us/step - loss: 1.7697

Epoch 00038: loss improved from 1.79165 to 1.76972, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 39/100
10000/10000 [==============================] - 2s 232us/step - loss: 1.7527

Epoch 00039: loss improved from 1.76972 to 1.75274, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 40/100
10000/10000 [==============================] - 2s 235us/step - loss: 1.7204

Epoch 00040: loss improved from 1.75274 to 1.72043, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 41/100
10000/10000 [==============================] - 2s 235us/step - loss: 1.7027

Epoch 00041: loss improved from 1.72043 to 1.70268, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 42/100
10000/10000 [==============================] - 2s 240us/step - loss: 1.6732

Epoch 00042: loss improved from 1.70268 to 1.67324, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 43/100
10000/10000 [==============================] - 2s 234us/step - loss: 1.6547

Epoch 00043: loss improved from 1.67324 to 1.65467, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 44/100
10000/10000 [==============================] - 2s 234us/step - loss: 1.6289

Epoch 00044: loss improved from 1.65467 to 1.62886, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 45/100
10000/10000 [==============================] - 2s 235us/step - loss: 1.6080

Epoch 00045: loss improved from 1.62886 to 1.60796, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 46/100
10000/10000 [==============================] - 2s 232us/step - loss: 1.5757

Epoch 00046: loss improved from 1.60796 to 1.57567, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 47/100
10000/10000 [==============================] - 2s 235us/step - loss: 1.5507

Epoch 00047: loss improved from 1.57567 to 1.55074, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 48/100
10000/10000 [==============================] - 2s 234us/step - loss: 1.5325

Epoch 00048: loss improved from 1.55074 to 1.53250, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 49/100
10000/10000 [==============================] - 2s 233us/step - loss: 1.5132

Epoch 00049: loss improved from 1.53250 to 1.51324, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 50/100
10000/10000 [==============================] - 2s 248us/step - loss: 1.4831

Epoch 00050: loss improved from 1.51324 to 1.48306, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 51/100
10000/10000 [==============================] - 3s 258us/step - loss: 1.4517

Epoch 00051: loss improved from 1.48306 to 1.45175, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 52/100
10000/10000 [==============================] - 2s 244us/step - loss: 1.4304

Epoch 00052: loss improved from 1.45175 to 1.43043, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 53/100
10000/10000 [==============================] - 2s 243us/step - loss: 1.4172

Epoch 00053: loss improved from 1.43043 to 1.41720, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 54/100
10000/10000 [==============================] - 2s 237us/step - loss: 1.3826

Epoch 00054: loss improved from 1.41720 to 1.38261, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 55/100
10000/10000 [==============================] - 2s 234us/step - loss: 1.3608

Epoch 00055: loss improved from 1.38261 to 1.36084, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 56/100
10000/10000 [==============================] - 2s 240us/step - loss: 1.3409

Epoch 00056: loss improved from 1.36084 to 1.34087, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 57/100
10000/10000 [==============================] - 2s 240us/step - loss: 1.3237

Epoch 00057: loss improved from 1.34087 to 1.32365, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 58/100
10000/10000 [==============================] - 2s 236us/step - loss: 1.2817

Epoch 00058: loss improved from 1.32365 to 1.28170, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 59/100
10000/10000 [==============================] - 2s 236us/step - loss: 1.2620

Epoch 00059: loss improved from 1.28170 to 1.26204, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 60/100
10000/10000 [==============================] - 2s 242us/step - loss: 1.2321

Epoch 00060: loss improved from 1.26204 to 1.23210, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 61/100
10000/10000 [==============================] - 2s 237us/step - loss: 1.2174

Epoch 00061: loss improved from 1.23210 to 1.21740, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 62/100
10000/10000 [==============================] - 2s 236us/step - loss: 1.2023

Epoch 00062: loss improved from 1.21740 to 1.20234, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 63/100
10000/10000 [==============================] - 2s 235us/step - loss: 1.1631

Epoch 00063: loss improved from 1.20234 to 1.16314, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 64/100
10000/10000 [==============================] - 2s 235us/step - loss: 1.1374

Epoch 00064: loss improved from 1.16314 to 1.13743, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 65/100
10000/10000 [==============================] - 2s 236us/step - loss: 1.1256

Epoch 00065: loss improved from 1.13743 to 1.12561, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 66/100
10000/10000 [==============================] - 2s 237us/step - loss: 1.1024

Epoch 00066: loss improved from 1.12561 to 1.10238, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 67/100
10000/10000 [==============================] - 2s 233us/step - loss: 1.0859

Epoch 00067: loss improved from 1.10238 to 1.08592, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 68/100
10000/10000 [==============================] - 2s 233us/step - loss: 1.0502

Epoch 00068: loss improved from 1.08592 to 1.05016, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 69/100
10000/10000 [==============================] - 2s 233us/step - loss: 1.0331

Epoch 00069: loss improved from 1.05016 to 1.03308, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 70/100
10000/10000 [==============================] - 2s 239us/step - loss: 1.0087

Epoch 00070: loss improved from 1.03308 to 1.00866, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 71/100
10000/10000 [==============================] - 2s 236us/step - loss: 0.9905

Epoch 00071: loss improved from 1.00866 to 0.99053, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 72/100
10000/10000 [==============================] - 2s 237us/step - loss: 0.9762

Epoch 00072: loss improved from 0.99053 to 0.97620, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 73/100
10000/10000 [==============================] - 2s 237us/step - loss: 0.9542

Epoch 00073: loss improved from 0.97620 to 0.95423, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 74/100
10000/10000 [==============================] - 2s 233us/step - loss: 0.9240

Epoch 00074: loss improved from 0.95423 to 0.92395, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 75/100
10000/10000 [==============================] - 2s 235us/step - loss: 0.9039

Epoch 00075: loss improved from 0.92395 to 0.90386, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 76/100
10000/10000 [==============================] - 2s 234us/step - loss: 0.8978

Epoch 00076: loss improved from 0.90386 to 0.89784, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 77/100
10000/10000 [==============================] - 2s 232us/step - loss: 0.8505

Epoch 00077: loss improved from 0.89784 to 0.85046, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 78/100
10000/10000 [==============================] - 2s 234us/step - loss: 0.8520

Epoch 00078: loss did not improve from 0.85046
Epoch 79/100
10000/10000 [==============================] - 2s 235us/step - loss: 0.8371

Epoch 00079: loss improved from 0.85046 to 0.83713, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 80/100
10000/10000 [==============================] - 2s 237us/step - loss: 0.8139

Epoch 00080: loss improved from 0.83713 to 0.81385, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 81/100
10000/10000 [==============================] - 2s 240us/step - loss: 0.7883

Epoch 00081: loss improved from 0.81385 to 0.78830, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 82/100
10000/10000 [==============================] - 2s 235us/step - loss: 0.7679

Epoch 00082: loss improved from 0.78830 to 0.76792, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 83/100
10000/10000 [==============================] - 2s 233us/step - loss: 0.7508

Epoch 00083: loss improved from 0.76792 to 0.75081, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 84/100
10000/10000 [==============================] - 2s 236us/step - loss: 0.7228

Epoch 00084: loss improved from 0.75081 to 0.72285, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 85/100
10000/10000 [==============================] - 2s 234us/step - loss: 0.7250

Epoch 00085: loss did not improve from 0.72285
Epoch 86/100
10000/10000 [==============================] - 2s 234us/step - loss: 0.7002

Epoch 00086: loss improved from 0.72285 to 0.70023, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 87/100
10000/10000 [==============================] - 2s 236us/step - loss: 0.6659

Epoch 00087: loss improved from 0.70023 to 0.66587, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 88/100
10000/10000 [==============================] - 2s 238us/step - loss: 0.6726

Epoch 00088: loss did not improve from 0.66587
Epoch 89/100
10000/10000 [==============================] - 2s 246us/step - loss: 0.6500

Epoch 00089: loss improved from 0.66587 to 0.65002, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 90/100
10000/10000 [==============================] - 2s 247us/step - loss: 0.6085

Epoch 00090: loss improved from 0.65002 to 0.60850, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 91/100
10000/10000 [==============================] - 2s 241us/step - loss: 0.6128

Epoch 00091: loss did not improve from 0.60850
Epoch 92/100
10000/10000 [==============================] - 2s 248us/step - loss: 0.6058

Epoch 00092: loss improved from 0.60850 to 0.60583, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 93/100
10000/10000 [==============================] - 2s 236us/step - loss: 0.5775

Epoch 00093: loss improved from 0.60583 to 0.57754, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 94/100
10000/10000 [==============================] - 2s 241us/step - loss: 0.5458

Epoch 00094: loss improved from 0.57754 to 0.54580, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 95/100
10000/10000 [==============================] - 2s 243us/step - loss: 0.5426

Epoch 00095: loss improved from 0.54580 to 0.54256, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 96/100
10000/10000 [==============================] - 2s 250us/step - loss: 0.5251

Epoch 00096: loss improved from 0.54256 to 0.52513, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 97/100
10000/10000 [==============================] - 2s 245us/step - loss: 0.5308

Epoch 00097: loss did not improve from 0.52513
Epoch 98/100
10000/10000 [==============================] - 2s 242us/step - loss: 0.5030

Epoch 00098: loss improved from 0.52513 to 0.50296, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
Epoch 99/100
10000/10000 [==============================] - 2s 240us/step - loss: 0.5077

Epoch 00099: loss did not improve from 0.50296
Epoch 100/100
10000/10000 [==============================] - 2s 236us/step - loss: 0.4672

Epoch 00100: loss improved from 0.50296 to 0.46722, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[103]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x1639783d940&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How do we make a given number of predictions (characters) based on this fitted model?</p>
<p>First we predict the next character after following any chunk of characters in the text of length equal to our chosen window size.  Then we remove the first character in our input sequence and tack our prediction onto the end.  This gives us a slightly changed sequence of inputs that still has length equal to the size of our window.  We then feed in this updated input sequence into the model to predict the another character.  Together then we have two predicted characters following our original input sequence.  Repeating this process N times gives us N predicted characters.</p>
<p>In the next Python cell we provide you with a completed function that does just this - it makes predictions when given a) a trained RNN model, b) a subset of (window_size) characters from the text, and c) a number of characters to predict (to follow our input subset).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># function that uses trained model to predict a desired number of future characters</span>
<span class="k">def</span> <span class="nf">predict_next_chars</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">input_chars</span><span class="p">,</span><span class="n">num_to_predict</span><span class="p">):</span>     
    <span class="c1"># create output</span>
    <span class="n">predicted_chars</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_to_predict</span><span class="p">):</span>
        <span class="c1"># convert this round&#39;s predicted characters to numerical input    </span>
        <span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_chars</span><span class="p">):</span>
            <span class="n">x_test</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">chars_to_indices</span><span class="p">[</span><span class="n">char</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

        <span class="c1"># make this round&#39;s prediction</span>
        <span class="n">test_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># translate numerical prediction back to characters</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_predict</span><span class="p">)</span>                           <span class="c1"># predict class of each test input</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">indices_to_chars</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> 

        <span class="c1"># update predicted_chars and input</span>
        <span class="n">predicted_chars</span><span class="o">+=</span><span class="n">d</span>
        <span class="n">input_chars</span><span class="o">+=</span><span class="n">d</span>
        <span class="n">input_chars</span> <span class="o">=</span> <span class="n">input_chars</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">predicted_chars</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='TODO_6'></a></p>
<p>With your trained model try a few subsets of the complete text as input - note the length of each must be exactly equal to the window size.  For each subset use the function above to predict the next 100 characters that follow each input.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># TODO: choose an input sequence and use the prediction function in the previous Python cell to predict 100 characters following it</span>
<span class="c1"># get an appropriately sized chunk of characters from the text</span>
<span class="n">start_inds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>

<span class="c1"># load in weights</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">build_part2_RNN</span><span class="p">(</span><span class="n">windowsize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">numchars</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;checkpoints/rnn_part2_CuLSTMm_small_textdata_weights-best.hdf5&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">start_inds</span><span class="p">:</span>
    <span class="n">start_index</span> <span class="o">=</span> <span class="n">s</span>
    <span class="n">input_chars</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span> <span class="n">start_index</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">]</span>

    <span class="c1"># use the prediction function</span>
    <span class="n">predict_input</span> <span class="o">=</span> <span class="n">predict_next_chars</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">input_chars</span><span class="p">,</span><span class="n">num_to_predict</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>

    <span class="c1"># print out input characters</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------&#39;</span><span class="p">)</span>
    <span class="n">input_line</span> <span class="o">=</span> <span class="s1">&#39;input chars = &#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span>  <span class="n">input_chars</span> <span class="o">+</span> <span class="s1">&#39;&quot;&#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">input_line</span><span class="p">)</span>

    <span class="c1"># print out predicted characters</span>
    <span class="n">line</span> <span class="o">=</span> <span class="s1">&#39;predicted chars = &#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span>  <span class="n">predict_input</span> <span class="o">+</span> <span class="s1">&#39;&quot;&#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>------------------
input chars = 
n his eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion a&#34;

predicted chars = 
ceryou hin ingo s prooo han see. i . a kall a the bunss sf pichine a uesan i whic  or angam mas!rris&#34;

------------------
input chars = 
pses and predominates the whole of her sex. it was not that he felt any emotion akin to love for ire&#34;

predicted chars = 
mmy mysssericlonen. the look the ther mist is ander and i savere an with hames so rern anlls houred &#34;

------------------
input chars = 
redominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. &#34;

predicted chars = 
i sould nogg por our teren. mese, to the chome mas soon on wissere. the listsed st the chave coursan&#34;

------------------
input chars = 
e of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and th&#34;

predicted chars = 
e peite uut so it he choure in. a s s a d art the rave be anserit indedestereculicl yoy ook the thot&#34;

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This looks ok, but not great.  Now lets try the same experiment with a larger chunk of the data - with the first 100,000 input/output pairs.</p>
<p>Tuning RNNs for a typical character dataset like the one we will use here is a computationally intensive endeavour and thus timely on a typical CPU.  Using a reasonably sized cloud-based GPU can speed up training by a factor of 10.  Also because of the long training time it is highly recommended that you carefully write the output of each step of your process to file.  This is so that all of your results are saved even if you close the web browser you're working out of, as the processes will continue processing in the background but variables/output in the notebook system will not update when you open it again.</p>
<p>In the next cell we show you how to create a text file in Python and record data to it.  This sort of setup can be used to record your final predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[107]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### A simple way to write output to file</span>
<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;my_test_output.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>              <span class="c1"># create an output file to write too</span>
<span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;this is only a test &#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>           <span class="c1"># print some output text</span>
<span class="n">x</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;the value of x is &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>    <span class="c1"># record a variable value</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>     

<span class="c1"># print out the contents of my_test_output.txt</span>
<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;my_test_output.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>              <span class="c1"># create an output file to write too</span>
<span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[107]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;this is only a test \nthe value of x is 2\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With this recording devices we can now more safely perform experiments on larger portions of the text.  In the next cell we will use the first 100,000 input/output pairs to train our RNN model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we fit our model to the dataset, then generate text using the trained model in precisely the same generation method applied before on the small dataset.</p>
<p><strong>Note:</strong> your generated words should be - by and large - more realistic than with the small dataset, but you won't be able to generate perfect English sentences even with this amount of data.  A rule of thumb: your model is working well if you generate sentences that largely contain real English words.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">my_answers</span> <span class="k">import</span> <span class="n">build_part2_RNN</span>
<span class="c1"># a small subset of our input/output pairs</span>
<span class="n">Xlarge</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">100000</span><span class="p">,:,:]</span>
<span class="n">ylarge</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">100000</span><span class="p">,:]</span>

<span class="n">checkpointfile_rnn2</span> <span class="o">=</span> <span class="s1">&#39;rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5&#39;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_part2_RNN</span><span class="p">(</span><span class="n">windowsize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">numchars</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="n">callbacks_rnn</span> <span class="o">=</span> <span class="n">Part2_RNN</span><span class="p">()</span><span class="o">.</span><span class="n">getcallbacks</span><span class="p">(</span><span class="n">checkpointstr</span><span class="o">=</span><span class="n">checkpointfile_rnn2</span><span class="p">,</span>
                                         <span class="n">eval_cb</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[109]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model.load_weights(&#39;checkpoints/rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5&#39;)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xlarge</span><span class="p">,</span> <span class="n">ylarge</span><span class="p">,</span> 
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
          <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_rnn</span><span class="p">,</span>
          <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/100
100000/100000 [==============================] - 17s 166us/step - loss: 2.8693

Epoch 00001: loss improved from inf to 2.86927, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 2/100
100000/100000 [==============================] - 15s 154us/step - loss: 2.5100

Epoch 00002: loss improved from 2.86927 to 2.50999, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 3/100
100000/100000 [==============================] - 15s 153us/step - loss: 2.2927

Epoch 00003: loss improved from 2.50999 to 2.29269, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 4/100
100000/100000 [==============================] - 15s 154us/step - loss: 2.1823

Epoch 00004: loss improved from 2.29269 to 2.18228, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 5/100
100000/100000 [==============================] - 15s 154us/step - loss: 2.1015

Epoch 00005: loss improved from 2.18228 to 2.10154, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 6/100
100000/100000 [==============================] - 15s 155us/step - loss: 2.0341

Epoch 00006: loss improved from 2.10154 to 2.03411, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 7/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.9792

Epoch 00007: loss improved from 2.03411 to 1.97922, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 8/100
100000/100000 [==============================] - 16s 155us/step - loss: 1.9312

Epoch 00008: loss improved from 1.97922 to 1.93124, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 9/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.8896

Epoch 00009: loss improved from 1.93124 to 1.88955, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 10/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.8520

Epoch 00010: loss improved from 1.88955 to 1.85200, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 11/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.8182

Epoch 00011: loss improved from 1.85200 to 1.81825, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 12/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.7876

Epoch 00012: loss improved from 1.81825 to 1.78764, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 13/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.7586

Epoch 00013: loss improved from 1.78764 to 1.75856, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 14/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.7293

Epoch 00014: loss improved from 1.75856 to 1.72933, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 15/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.7037

Epoch 00015: loss improved from 1.72933 to 1.70366, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 16/100
100000/100000 [==============================] - 15s 155us/step - loss: 1.6778

Epoch 00016: loss improved from 1.70366 to 1.67783, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 17/100
100000/100000 [==============================] - 15s 155us/step - loss: 1.6534

Epoch 00017: loss improved from 1.67783 to 1.65337, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 18/100
100000/100000 [==============================] - 16s 155us/step - loss: 1.6295

Epoch 00018: loss improved from 1.65337 to 1.62954, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 19/100
100000/100000 [==============================] - 16s 156us/step - loss: 1.6071

Epoch 00019: loss improved from 1.62954 to 1.60713, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 20/100
100000/100000 [==============================] - 15s 155us/step - loss: 1.5848

Epoch 00020: loss improved from 1.60713 to 1.58482, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 21/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.5621

Epoch 00021: loss improved from 1.58482 to 1.56208, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 22/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.5415

Epoch 00022: loss improved from 1.56208 to 1.54152, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 23/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.5210

Epoch 00023: loss improved from 1.54152 to 1.52096, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 24/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.5000

Epoch 00024: loss improved from 1.52096 to 1.50001, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 25/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.4793

Epoch 00025: loss improved from 1.50001 to 1.47927, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 26/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.4596

Epoch 00026: loss improved from 1.47927 to 1.45957, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 27/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.4399

Epoch 00027: loss improved from 1.45957 to 1.43986, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 28/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.4192

Epoch 00028: loss improved from 1.43986 to 1.41924, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 29/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.4000

Epoch 00029: loss improved from 1.41924 to 1.39998, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 30/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.3796

Epoch 00030: loss improved from 1.39998 to 1.37961, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 31/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.3609

Epoch 00031: loss improved from 1.37961 to 1.36089, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 32/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.3409

Epoch 00032: loss improved from 1.36089 to 1.34092, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 33/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.3219

Epoch 00033: loss improved from 1.34092 to 1.32191, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 34/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.3016

Epoch 00034: loss improved from 1.32191 to 1.30165, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 35/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.2825

Epoch 00035: loss improved from 1.30165 to 1.28254, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 36/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.2622

Epoch 00036: loss improved from 1.28254 to 1.26217, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 37/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.2438

Epoch 00037: loss improved from 1.26217 to 1.24377, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 38/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.2231

Epoch 00038: loss improved from 1.24377 to 1.22306, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 39/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.2042

Epoch 00039: loss improved from 1.22306 to 1.20417, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 40/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.1863

Epoch 00040: loss improved from 1.20417 to 1.18625, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 41/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.1653

Epoch 00041: loss improved from 1.18625 to 1.16534, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 42/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.1469

Epoch 00042: loss improved from 1.16534 to 1.14690, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 43/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.1279

Epoch 00043: loss improved from 1.14690 to 1.12786, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 44/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.1095

Epoch 00044: loss improved from 1.12786 to 1.10947, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 45/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.0909

Epoch 00045: loss improved from 1.10947 to 1.09095, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 46/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.0711

Epoch 00046: loss improved from 1.09095 to 1.07106, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 47/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.0530

Epoch 00047: loss improved from 1.07106 to 1.05297, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 48/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.0357

Epoch 00048: loss improved from 1.05297 to 1.03574, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 49/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.0170

Epoch 00049: loss improved from 1.03574 to 1.01701, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 50/100
100000/100000 [==============================] - 15s 154us/step - loss: 1.0009

Epoch 00050: loss improved from 1.01701 to 1.00092, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 51/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.9827

Epoch 00051: loss improved from 1.00092 to 0.98272, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 52/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.9649

Epoch 00052: loss improved from 0.98272 to 0.96486, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 53/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.9511

Epoch 00053: loss improved from 0.96486 to 0.95112, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 54/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.9354

Epoch 00054: loss improved from 0.95112 to 0.93539, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 55/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.9201

Epoch 00055: loss improved from 0.93539 to 0.92005, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 56/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.9045

Epoch 00056: loss improved from 0.92005 to 0.90445, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 57/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.8893

Epoch 00057: loss improved from 0.90445 to 0.88926, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 58/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.8738

Epoch 00058: loss improved from 0.88926 to 0.87381, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 59/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.8608

Epoch 00059: loss improved from 0.87381 to 0.86081, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 60/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.8458

Epoch 00060: loss improved from 0.86081 to 0.84575, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 61/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.8334

Epoch 00061: loss improved from 0.84575 to 0.83336, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 62/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.8179

Epoch 00062: loss improved from 0.83336 to 0.81790, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 63/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.8077

Epoch 00063: loss improved from 0.81790 to 0.80768, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 64/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7960

Epoch 00064: loss improved from 0.80768 to 0.79604, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 65/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7828

Epoch 00065: loss improved from 0.79604 to 0.78284, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 66/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7709

Epoch 00066: loss improved from 0.78284 to 0.77094, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 67/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7612

Epoch 00067: loss improved from 0.77094 to 0.76121, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 68/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7494

Epoch 00068: loss improved from 0.76121 to 0.74938, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 69/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7367

Epoch 00069: loss improved from 0.74938 to 0.73668, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 70/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7279

Epoch 00070: loss improved from 0.73668 to 0.72790, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 71/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7182

Epoch 00071: loss improved from 0.72790 to 0.71820, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 72/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7091

Epoch 00072: loss improved from 0.71820 to 0.70911, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 73/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.7003

Epoch 00073: loss improved from 0.70911 to 0.70035, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 74/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6899

Epoch 00074: loss improved from 0.70035 to 0.68993, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 75/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6810

Epoch 00075: loss improved from 0.68993 to 0.68096, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 76/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6730

Epoch 00076: loss improved from 0.68096 to 0.67305, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 77/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6646

Epoch 00077: loss improved from 0.67305 to 0.66459, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 78/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6563

Epoch 00078: loss improved from 0.66459 to 0.65629, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 79/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6498

Epoch 00079: loss improved from 0.65629 to 0.64976, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 80/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6396

Epoch 00080: loss improved from 0.64976 to 0.63959, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 81/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6343

Epoch 00081: loss improved from 0.63959 to 0.63427, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 82/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6264

Epoch 00082: loss improved from 0.63427 to 0.62637, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 83/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6185

Epoch 00083: loss improved from 0.62637 to 0.61845, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 84/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6121

Epoch 00084: loss improved from 0.61845 to 0.61206, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 85/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.6039

Epoch 00085: loss improved from 0.61206 to 0.60388, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 86/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5992

Epoch 00086: loss improved from 0.60388 to 0.59918, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 87/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5910

Epoch 00087: loss improved from 0.59918 to 0.59098, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 88/100
100000/100000 [==============================] - 15s 155us/step - loss: 0.5849

Epoch 00088: loss improved from 0.59098 to 0.58495, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 89/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5797

Epoch 00089: loss improved from 0.58495 to 0.57967, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 90/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5735

Epoch 00090: loss improved from 0.57967 to 0.57349, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 91/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5679

Epoch 00091: loss improved from 0.57349 to 0.56791, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 92/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5600

Epoch 00092: loss improved from 0.56791 to 0.55998, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 93/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5563

Epoch 00093: loss improved from 0.55998 to 0.55635, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 94/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5500

Epoch 00094: loss improved from 0.55635 to 0.54997, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 95/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5445

Epoch 00095: loss improved from 0.54997 to 0.54452, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 96/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5388

Epoch 00096: loss improved from 0.54452 to 0.53877, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 97/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5344

Epoch 00097: loss improved from 0.53877 to 0.53442, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 98/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5286

Epoch 00098: loss improved from 0.53442 to 0.52863, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 99/100
100000/100000 [==============================] - 15s 154us/step - loss: 0.5256

Epoch 00099: loss improved from 0.52863 to 0.52561, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
Epoch 100/100
100000/100000 [==============================] - 15s 155us/step - loss: 0.5162

Epoch 00100: loss improved from 0.52561 to 0.51623, saving model to F:\git\aind\deeplearn\aind2-rnn\checkpoints\rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[109]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x163992c1438&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[110]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># TODO: choose an input sequence and use the prediction function in the previous Python cell to predict 100 characters following it</span>

<span class="c1"># get an appropriately sized chunk of characters from the text</span>
<span class="n">start_inds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">500</span><span class="p">]</span>

<span class="c1"># load in weights</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">build_part2_RNN</span><span class="p">(</span><span class="n">windowsize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">numchars</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;checkpoints/rnn_part2_CuLSTMm_LARGE_textdata_weights-best.hdf5&#39;</span><span class="p">)</span>

<span class="c1"># save output</span>
<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;text_gen_output/RNN_large_textdata_output.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>  <span class="c1"># create an output file to write too</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">start_inds</span><span class="p">:</span>
    <span class="n">start_index</span> <span class="o">=</span> <span class="n">s</span>
    <span class="n">input_chars</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span> <span class="n">start_index</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">]</span>

    <span class="c1"># use the prediction function</span>
    <span class="n">predict_input</span> <span class="o">=</span> <span class="n">predict_next_chars</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">input_chars</span><span class="p">,</span><span class="n">num_to_predict</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>

    <span class="c1"># print out input characters</span>
    <span class="n">line</span> <span class="o">=</span> <span class="s1">&#39;-------------------&#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

    <span class="n">input_line</span> <span class="o">=</span> <span class="s1">&#39;input chars = &#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span>  <span class="n">input_chars</span> <span class="o">+</span> <span class="s1">&#39;&quot;&#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">input_line</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">input_line</span><span class="p">)</span>

    <span class="c1"># print out predicted characters</span>
    <span class="n">predict_line</span> <span class="o">=</span> <span class="s1">&#39;predicted chars = &#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span>  <span class="n">predict_input</span> <span class="o">+</span> <span class="s1">&#39;&quot;&#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict_line</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">predict_line</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>-------------------

input chars = 
akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, p&#34;

predicted chars = 
rom holmes. i shall not she wime he room his byeart, peeshing he ease ever then if you me and from i&#34;

-------------------

input chars = 
recise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing mach&#34;

predicted chars = 
 sparied to me, showing might he he entered, the same to my be seell to door and i have his noters o&#34;

-------------------

input chars = 
server excellent for drawing the veil from men s motives and actions. but for the trained reasoner t&#34;

predicted chars = 
o the ross that it mockst who had come tagked at the rusmien door, and his brey upbly the bass, this&#34;

</pre>
</div>
</div>

</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
